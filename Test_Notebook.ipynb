{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Multi-Model TestBook",
   "id": "4e7d006d2ae7da92"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "8434c5bc71e52c34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:32:44.750892Z",
     "start_time": "2025-08-02T14:32:41.973265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Imports\n",
    "import os\n",
    "# MUST be set before importing any PyTorch/CUDA modules\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "\n",
    "import torch\n",
    "# Configure PyTorch for full determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from torchmetrics import Accuracy, F1Score, Precision, Recall\n",
    "from torchvision.transforms import v2\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re"
   ],
   "id": "f392f325a38ed982",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ViT Branch",
   "id": "cb3b586f6635df3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset",
   "id": "9008faffcdf4e134"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T16:42:44.062505Z",
     "start_time": "2025-08-01T16:42:44.052235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enhanced Data Preparation with Stratified Splitting\n",
    "class FireDataset(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir, augmented_dir,\n",
    "                 batch_size=32, num_workers=4, train_augmented_multiplicity=4,\n",
    "                 regenerate=False):\n",
    "        \"\"\"\n",
    "        Custom PyTorch Lightning DataModule for fire detection dataset.\n",
    "\n",
    "        Args:\n",
    "            data_dir: Root directory containing original image dataset\n",
    "            augmented_dir: Directory to save processed images\n",
    "            batch_size: Number of samples per batch\n",
    "            num_workers: Parallel threads for data loading\n",
    "            train_augmented_multiplicity: Multiplier for training data augmentation\n",
    "            regenerate: Force regeneration of augmented dataset\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.augmented_dir = augmented_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.train_augmented_multiplicity = train_augmented_multiplicity\n",
    "        self.regenerate = regenerate\n",
    "        self.classes = None\n",
    "        self.transform = None\n",
    "        self.augment = None\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        \"\"\"Prepares datasets and saves augmented images\"\"\"\n",
    "        # Define transforms\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        self.augment = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        # Load base dataset\n",
    "        base_dataset = datasets.ImageFolder(root=self.data_dir, transform=None)\n",
    "        self.classes = base_dataset.classes\n",
    "        targets = [s[1] for s in base_dataset.samples]\n",
    "\n",
    "        # Create splits\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        train_idx, test_idx = next(skf.split(np.zeros(len(targets)), targets))\n",
    "        val_idx, test_idx = train_test_split(test_idx, test_size=0.5, random_state=42)\n",
    "\n",
    "        # Save augmented datasets\n",
    "        self._save_augmented_dataset(base_dataset, train_idx, val_idx, test_idx)\n",
    "\n",
    "        # Create datasets from saved images\n",
    "        self.train_dataset = datasets.ImageFolder(\n",
    "            root=os.path.join(self.augmented_dir, \"train\"),\n",
    "            transform=self.transform  # Only standard transform for saved augmented images\n",
    "        )\n",
    "        self.val_dataset = datasets.ImageFolder(\n",
    "            root=os.path.join(self.augmented_dir, \"val\"),\n",
    "            transform=self.transform\n",
    "        )\n",
    "        self.test_dataset = datasets.ImageFolder(\n",
    "            root=os.path.join(self.augmented_dir, \"test\"),\n",
    "            transform=self.transform\n",
    "        )\n",
    "\n",
    "    def _save_augmented_dataset(self, base_dataset, train_idx, val_idx, test_idx):\n",
    "        \"\"\"Saves processed images to filesystem\"\"\"\n",
    "        # Create output directories\n",
    "        splits = {\n",
    "            \"train\": (train_idx, self.augment, self.train_augmented_multiplicity),\n",
    "            \"val\": (val_idx, self.transform, 1),\n",
    "            \"test\": (test_idx, self.transform, 1)\n",
    "        }\n",
    "\n",
    "        # Check if regeneration is needed\n",
    "        if not self.regenerate and all(os.path.exists(os.path.join(self.augmented_dir, split)) for split in splits):\n",
    "            print(\"Using existing augmented dataset\")\n",
    "            return\n",
    "\n",
    "        print(\"Generating and saving augmented dataset...\")\n",
    "        for split_name, (indices, transform, multiplicity) in splits.items():\n",
    "            split_dir = os.path.join(self.augmented_dir, split_name)\n",
    "            for class_name in self.classes:\n",
    "                os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n",
    "\n",
    "            for idx in indices:\n",
    "                img, label = base_dataset[idx]\n",
    "                class_name = self.classes[label]\n",
    "\n",
    "                for aug_idx in range(multiplicity):\n",
    "                    # Apply transformations\n",
    "                    transformed_img = transform(img)\n",
    "\n",
    "                    # Convert back to PIL for saving\n",
    "                    img_pil = self._tensor_to_pil(transformed_img)\n",
    "\n",
    "                    # Save with unique filename\n",
    "                    original_name = os.path.splitext(os.path.basename(base_dataset.samples[idx][0]))[0]\n",
    "                    save_path = os.path.join(split_dir, class_name, f\"{original_name}_aug{aug_idx}.jpg\")\n",
    "                    img_pil.save(save_path)\n",
    "\n",
    "    def _tensor_to_pil(self, tensor):\n",
    "        \"\"\"Converts normalized tensor back to PIL Image\"\"\"\n",
    "        # Reverse normalization\n",
    "        inverse_norm = transforms.Normalize(\n",
    "            mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "            std=[1/0.229, 1/0.224, 1/0.225]\n",
    "        )\n",
    "        tensor = inverse_norm(tensor)\n",
    "        tensor = torch.clamp(tensor, 0, 1)\n",
    "        tensor = tensor.mul(255).byte()\n",
    "        return transforms.ToPILImage()(tensor.cpu())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers\n",
    "        )"
   ],
   "id": "a79ced9e145f3ab",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### ViT Model",
   "id": "621cdc74891f368f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:34:07.294978Z",
     "start_time": "2025-08-02T14:34:07.286229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vision Transformer (ViT) Feature Extractor with Classification Head\n",
    "class FireFeatureExtractorViT(pl.LightningModule):\n",
    "    def __init__(self, config=None):\n",
    "        \"\"\"\n",
    "        Custom Vision Transformer model for fire detection with feature extraction capability.\n",
    "\n",
    "        Args:\n",
    "            config: Configuration dictionary with hyperparameters. Defaults to empty dict.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.config = config or {}\n",
    "        self.save_hyperparameters(config)  # Save config for checkpointing\n",
    "\n",
    "        # Initialize with pretrained weights if specified, otherwise random initialization\n",
    "        weights = ViT_B_16_Weights.IMAGENET1K_V1 if self.config.get(\"pretrained\", True) else None\n",
    "        self.vit = vit_b_16(weights=weights)\n",
    "\n",
    "        # Freeze backbone parameters if requested (transfer learning)\n",
    "        if self.config.get(\"freeze_backbone\", True):\n",
    "            for param in self.vit.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Replace classification head with identity to output raw features (768-dim)\n",
    "        self.vit.heads = nn.Identity()\n",
    "\n",
    "        # Custom classification head for binary fire detection\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768, 256),  # Feature compression layer\n",
    "            nn.ReLU(),            # Activation for non-linearity\n",
    "            nn.BatchNorm1d(256),  # Normalization for stability\n",
    "            nn.Dropout(self.config.get(\"dropout_rate\", 0.5)),  # Regularization\n",
    "            nn.Linear(256, 1)     # Binary classification output (fire/no-fire)\n",
    "        )\n",
    "\n",
    "        # Loss function with class weighting to handle imbalanced datasets\n",
    "        self.criterion = nn.BCEWithLogitsLoss(\n",
    "            pos_weight=torch.tensor(self.config.get(\"pos_weight\", 1.0))\n",
    "        )\n",
    "\n",
    "        # Accuracy metrics for different phases\n",
    "        self.train_acc = Accuracy(task='binary')\n",
    "        self.val_acc = Accuracy(task='binary')\n",
    "        self.test_acc = Accuracy(task='binary')\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Feature extraction pass - returns 768-dimensional embeddings\"\"\"\n",
    "        return self.vit(x)\n",
    "\n",
    "    def classify(self, x):\n",
    "        \"\"\"Full classification pass (features + classifier head)\"\"\"\n",
    "        features = self.vit(x)  # Extract visual features\n",
    "        return self.classifier(features).squeeze(1)  # Remove extra dimension\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure optimizer and learning rate scheduler\"\"\"\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.config.get(\"lr\", 1e-4),                # Default learning rate\n",
    "            weight_decay=self.config.get(\"weight_decay\", 1e-4)  # L2 regularization\n",
    "        )\n",
    "\n",
    "        # Learning rate scheduler that reduces when validation accuracy plateaus\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='max',     # Monitor validation accuracy (maximize)\n",
    "            factor=0.5,     # Reduce LR by half when triggered\n",
    "            patience=3,     # Wait 3 epochs without improvement\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_acc\",  # Watch validation accuracy\n",
    "                \"frequency\": 1         # Check every epoch\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Single training step with loss calculation and metrics logging\"\"\"\n",
    "        images, labels = batch\n",
    "        labels = labels.float()  # Convert to float for BCE loss\n",
    "\n",
    "        # Forward pass through classifier\n",
    "        outputs = self.classify(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "\n",
    "        # Convert logits to binary predictions (threshold=0.5)\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        self.train_acc(preds, labels)  # Update accuracy metric\n",
    "\n",
    "        # Log training metrics (step-level loss, epoch-level accuracy)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", self.train_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"Single validation step with metrics calculation\"\"\"\n",
    "        images, labels = batch\n",
    "        labels = labels.float()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self.classify(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        self.val_acc(preds, labels)\n",
    "\n",
    "        # Log validation metrics (epoch-level only)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_acc, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"Single test step for final evaluation\"\"\"\n",
    "        images, labels = batch\n",
    "        labels = labels.float()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = self.classify(images)\n",
    "        loss = self.criterion(outputs, labels)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        self.test_acc(preds, labels)\n",
    "\n",
    "        # Log test metrics\n",
    "        self.log(\"test_loss\", loss, on_epoch=True)\n",
    "        self.log(\"test_acc\", self.test_acc, on_epoch=True)\n",
    "\n",
    "        return loss"
   ],
   "id": "2e23c906e2078afc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "a71bab9e32dc55f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T22:00:24.444779Z",
     "start_time": "2025-07-31T22:00:24.439258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training Function\n",
    "def train_feature_extractor(num_epochs):\n",
    "    \"\"\"\n",
    "    Trains the fire feature extractor model end-to-end.\n",
    "\n",
    "    Args:\n",
    "        num_epochs: Number of training epochs\n",
    "\n",
    "    Returns:\n",
    "        model: Trained feature extractor model\n",
    "        trainer: PyTorch Lightning trainer object\n",
    "        data: Data module used for training\n",
    "    \"\"\"\n",
    "    # Initialize data module with default batch size\n",
    "    data = FireDataset(\n",
    "        data_dir=\"dataset/raw/RGB\",\n",
    "        augmented_dir=\"dataset/vit\",  # Use saved augmented images\n",
    "        batch_size=32,\n",
    "        regenerate=False,  # Set to True to regenerate images\n",
    "        train_augmented_multiplicity=5\n",
    "    )\n",
    "    data.setup()  # Prepare datasets and transformations\n",
    "\n",
    "    # Calculate class imbalance weight for positive samples\n",
    "    # Example: [non-fire_count, fire_count] - replace with actual counts\n",
    "    class_counts = [1000, 200]  # Example: [negative_class, positive_class]\n",
    "    pos_weight = class_counts[0] / class_counts[1]  # weight = negative_count / positive_count\n",
    "\n",
    "    # Model configuration parameters\n",
    "    config = {\n",
    "        \"lr\": 1e-4,               # Learning rate\n",
    "        \"weight_decay\": 1e-4,      # L2 regularization strength\n",
    "        \"freeze_backbone\": True,   # Freeze ViT weights during training\n",
    "        \"pretrained\": True,        # Use pretrained ViT weights\n",
    "        \"dropout_rate\": 0.5,       # Dropout probability in classifier\n",
    "        \"pos_weight\": pos_weight   # Class imbalance compensation\n",
    "    }\n",
    "\n",
    "    # Initialize model with configuration\n",
    "    model = FireFeatureExtractorViT(config)\n",
    "\n",
    "    # Model checkpoint callback - saves best model based on validation accuracy\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        monitor=\"val_acc\",         # Metric to monitor\n",
    "        mode=\"max\",                # Maximize validation accuracy\n",
    "        save_top_k=1,              # Save only the best model\n",
    "        filename=\"best_feature_extractor\"  # Checkpoint filename\n",
    "    )\n",
    "\n",
    "    # Create PyTorch Lightning trainer\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=num_epochs,    # Training duration\n",
    "        callbacks=[checkpoint],    # Attach checkpoint callback\n",
    "        accelerator=\"auto\",        # Automatically select hardware (GPU/CPU)\n",
    "        devices=1,                # Use single device\n",
    "        log_every_n_steps=10,     # Log metrics every 10 batches\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.fit(model, data)\n",
    "\n",
    "    # Evaluate on test set after training\n",
    "    test_result = trainer.test(model, dataloaders=data.test_dataloader())\n",
    "    print(f\"Test Accuracy: {test_result[0]['test_acc']:.4f}\")\n",
    "\n",
    "    return model, trainer, data\n",
    "\n",
    "# Save Feature Extractor\n",
    "def save_feature_extractor(trainer, path=\"feature_extractor.pth\"):\n",
    "    \"\"\"\n",
    "    Saves the trained feature extractor as a Lightning checkpoint.\n",
    "\n",
    "    Preserves model weights, hyperparameters, and optimizer state.\n",
    "\n",
    "    Args:\n",
    "        trainer: Trainer instance containing the model\n",
    "        path: Output file path for checkpoint\n",
    "    \"\"\"\n",
    "    # Save entire model state including metadata and optimizer\n",
    "    trainer.save_checkpoint(path)\n",
    "    print(f\"Full Lightning checkpoint saved to {path}\")\n",
    "\n",
    "# Feature Extraction Function\n",
    "def extract_features(model, dataloader):\n",
    "    \"\"\"\n",
    "    Extracts feature vectors from images using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained feature extractor model\n",
    "        dataloader: DataLoader providing image batches\n",
    "\n",
    "    Returns:\n",
    "        features: 2D array of extracted features [n_samples, 768]\n",
    "        labels: 1D array of corresponding labels\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    features = []  # Storage for feature vectors\n",
    "    labels = []    # Storage for corresponding labels\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        for images, batch_labels in dataloader:\n",
    "            # Move images to same device as model (GPU/CPU)\n",
    "            images = images.to(model.device)\n",
    "\n",
    "            # Extract features (768-dimensional vectors)\n",
    "            batch_features = model(images)\n",
    "\n",
    "            # Store results (move to CPU for numpy conversion)\n",
    "            features.append(batch_features.cpu().numpy())\n",
    "            labels.append(batch_labels.numpy())\n",
    "\n",
    "    # Combine all batches into single arrays\n",
    "    return np.concatenate(features), np.concatenate(labels)"
   ],
   "id": "36460fdbf73c95d9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T22:07:18.504096Z",
     "start_time": "2025-07-31T22:00:26.763897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- TRAINING PIPELINE EXECUTION ---\n",
    "# Clear GPU memory cache to avoid out-of-memory errors\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Start performance timer\n",
    "start = time.time()\n",
    "\n",
    "# Step 1: Train the feature extractor model\n",
    "print(\"Training feature extractor...\")\n",
    "trained_model, trainer, data = train_feature_extractor(num_epochs=40)\n",
    "\n",
    "# Step 2: Save the trained model for future use\n",
    "save_feature_extractor(trainer, \"Saved_Features/ViT_fire_feature_extractor.pth\")\n",
    "\n",
    "# Step 3: Load the feature extractor (without classifier head)\n",
    "print(\"\\nLoading feature extractor for inference...\")\n",
    "# Initialize model with default configuration\n",
    "feature_extractor = FireFeatureExtractorViT()\n",
    "# Load weights while ignoring classifier parameters (strict=False)\n",
    "feature_extractor.load_state_dict(\n",
    "    torch.load(\"Saved_Features/ViT_fire_feature_extractor.pth\"),\n",
    "    strict=False  # Required since we're discarding the classifier\n",
    ")\n",
    "feature_extractor.eval()  # Set to evaluation mode\n",
    "\n",
    "# Step 4: Extract feature vectors from training data\n",
    "print(\"\\nExtracting features from training dataset...\")\n",
    "train_features, train_labels = extract_features(\n",
    "    feature_extractor,\n",
    "    data.train_dataloader()\n",
    ")\n",
    "print(f\"Extracted {len(train_features)} feature vectors (768-dim each)\")\n",
    "\n",
    "# Step 5: Demonstrate feature usage for downstream models\n",
    "print(\"\\nFeatures ready for transfer learning or multi-model systems:\")\n",
    "print(f\"Feature vector shape: {train_features[0].shape}\")  # Should be (768,)\n",
    "print(f\"Sample feature (first 10 values): {train_features[0][:10]}...\")\n",
    "\n",
    "# Calculate and display execution time\n",
    "time_taken = time.time() - start\n",
    "print(f\"\\nTotal Execution Time: {time_taken:.2f} seconds ({time_taken / 60:.2f} minutes)\")"
   ],
   "id": "ffa30a937d473a30",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training feature extractor...\n",
      "Generating and saving augmented dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/carbs/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type              | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | vit        | VisionTransformer | 85.8 M | train\n",
      "1 | classifier | Sequential        | 197 K  | train\n",
      "2 | criterion  | BCEWithLogitsLoss | 0      | train\n",
      "3 | train_acc  | BinaryAccuracy    | 0      | train\n",
      "4 | val_acc    | BinaryAccuracy    | 0      | train\n",
      "5 | test_acc   | BinaryAccuracy    | 0      | train\n",
      "---------------------------------------------------------\n",
      "197 K     Trainable params\n",
      "85.8 M    Non-trainable params\n",
      "86.0 M    Total params\n",
      "343.985   Total estimated model params size (MB)\n",
      "161       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing augmented dataset\n",
      "Epoch 0: 100%|██████████| 81/81 [02:19<00:00,  0.58it/s, v_num=21, train_loss_step=0.378]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 1/2 [00:01<00:01,  0.71it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 2/2 [00:02<00:00,  0.72it/s]\u001B[A\n",
      "Epoch 1:  16%|█▌        | 13/81 [00:25<02:13,  0.51it/s, v_num=21, train_loss_step=0.229, val_loss=0.277, val_acc=0.953, train_loss_epoch=0.472, train_acc=0.843]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:48\u001B[39m, in \u001B[36m_call_and_handle_interrupt\u001B[39m\u001B[34m(trainer, trainer_fn, *args, **kwargs)\u001B[39m\n\u001B[32m     47\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrainer_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     50\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m _TunerExitException:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:599\u001B[39m, in \u001B[36mTrainer._fit_impl\u001B[39m\u001B[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[39m\n\u001B[32m    593\u001B[39m ckpt_path = \u001B[38;5;28mself\u001B[39m._checkpoint_connector._select_ckpt_path(\n\u001B[32m    594\u001B[39m     \u001B[38;5;28mself\u001B[39m.state.fn,\n\u001B[32m    595\u001B[39m     ckpt_path,\n\u001B[32m    596\u001B[39m     model_provided=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m    597\u001B[39m     model_connected=\u001B[38;5;28mself\u001B[39m.lightning_module \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    598\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m599\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mckpt_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    601\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.state.stopped\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1012\u001B[39m, in \u001B[36mTrainer._run\u001B[39m\u001B[34m(self, model, ckpt_path)\u001B[39m\n\u001B[32m   1009\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m   1010\u001B[39m \u001B[38;5;66;03m# RUN THE TRAINER\u001B[39;00m\n\u001B[32m   1011\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1012\u001B[39m results = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_stage\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1014\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n\u001B[32m   1015\u001B[39m \u001B[38;5;66;03m# POST-Training CLEAN UP\u001B[39;00m\n\u001B[32m   1016\u001B[39m \u001B[38;5;66;03m# ----------------------------\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:1056\u001B[39m, in \u001B[36mTrainer._run_stage\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1055\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.autograd.set_detect_anomaly(\u001B[38;5;28mself\u001B[39m._detect_anomaly):\n\u001B[32m-> \u001B[39m\u001B[32m1056\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfit_loop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1057\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:216\u001B[39m, in \u001B[36m_FitLoop.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    215\u001B[39m \u001B[38;5;28mself\u001B[39m.on_advance_start()\n\u001B[32m--> \u001B[39m\u001B[32m216\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    217\u001B[39m \u001B[38;5;28mself\u001B[39m.on_advance_end()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:455\u001B[39m, in \u001B[36m_FitLoop.advance\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    454\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m._data_fetcher \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m455\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mepoch_loop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_data_fetcher\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py:152\u001B[39m, in \u001B[36m_TrainingEpochLoop.run\u001B[39m\u001B[34m(self, data_fetcher)\u001B[39m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m152\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43madvance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_fetcher\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    153\u001B[39m     \u001B[38;5;28mself\u001B[39m.on_advance_end(data_fetcher)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/training_epoch_loop.py:344\u001B[39m, in \u001B[36m_TrainingEpochLoop.advance\u001B[39m\u001B[34m(self, data_fetcher)\u001B[39m\n\u001B[32m    342\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m trainer.lightning_module.automatic_optimization:\n\u001B[32m    343\u001B[39m     \u001B[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m344\u001B[39m     batch_output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mautomatic_optimization\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43moptimizers\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    345\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py:192\u001B[39m, in \u001B[36m_AutomaticOptimization.run\u001B[39m\u001B[34m(self, optimizer, batch_idx, kwargs)\u001B[39m\n\u001B[32m    187\u001B[39m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[32m    188\u001B[39m \u001B[38;5;66;03m# BACKWARD PASS\u001B[39;00m\n\u001B[32m    189\u001B[39m \u001B[38;5;66;03m# ------------------------------\u001B[39;00m\n\u001B[32m    190\u001B[39m \u001B[38;5;66;03m# gradient update with accumulated gradients\u001B[39;00m\n\u001B[32m    191\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m192\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_optimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    194\u001B[39m result = closure.consume_result()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py:270\u001B[39m, in \u001B[36m_AutomaticOptimization._optimizer_step\u001B[39m\u001B[34m(self, batch_idx, train_step_and_backward_closure)\u001B[39m\n\u001B[32m    269\u001B[39m \u001B[38;5;66;03m# model hook\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m270\u001B[39m \u001B[43mcall\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_lightning_module_hook\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    271\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    272\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43moptimizer_step\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    273\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcurrent_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    274\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    275\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    276\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_step_and_backward_closure\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    277\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    279\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m should_accumulate:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:176\u001B[39m, in \u001B[36m_call_lightning_module_hook\u001B[39m\u001B[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001B[39m\n\u001B[32m    175\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m trainer.profiler.profile(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m[LightningModule]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpl_module.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m176\u001B[39m     output = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    178\u001B[39m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/core/module.py:1328\u001B[39m, in \u001B[36mLightningModule.optimizer_step\u001B[39m\u001B[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001B[39m\n\u001B[32m   1304\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001B[39;00m\n\u001B[32m   1305\u001B[39m \u001B[33;03mthe optimizer.\u001B[39;00m\n\u001B[32m   1306\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   1326\u001B[39m \n\u001B[32m   1327\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1328\u001B[39m \u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m=\u001B[49m\u001B[43moptimizer_closure\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/core/optimizer.py:154\u001B[39m, in \u001B[36mLightningOptimizer.step\u001B[39m\u001B[34m(self, closure, **kwargs)\u001B[39m\n\u001B[32m    153\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m._strategy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m154\u001B[39m step_output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_strategy\u001B[49m\u001B[43m.\u001B[49m\u001B[43moptimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    156\u001B[39m \u001B[38;5;28mself\u001B[39m._on_after_step()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py:239\u001B[39m, in \u001B[36mStrategy.optimizer_step\u001B[39m\u001B[34m(self, optimizer, closure, model, **kwargs)\u001B[39m\n\u001B[32m    238\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model, pl.LightningModule)\n\u001B[32m--> \u001B[39m\u001B[32m239\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mprecision_plugin\u001B[49m\u001B[43m.\u001B[49m\u001B[43moptimizer_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/plugins/precision/precision.py:123\u001B[39m, in \u001B[36mPrecision.optimizer_step\u001B[39m\u001B[34m(self, optimizer, model, closure, **kwargs)\u001B[39m\n\u001B[32m    122\u001B[39m closure = partial(\u001B[38;5;28mself\u001B[39m._wrap_closure, model, optimizer, closure)\n\u001B[32m--> \u001B[39m\u001B[32m123\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m=\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:485\u001B[39m, in \u001B[36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    481\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    482\u001B[39m                 \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    483\u001B[39m             )\n\u001B[32m--> \u001B[39m\u001B[32m485\u001B[39m out = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    486\u001B[39m \u001B[38;5;28mself\u001B[39m._optimizer_step_code()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:79\u001B[39m, in \u001B[36m_use_grad_for_differentiable.<locals>._use_grad\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     78\u001B[39m     torch._dynamo.graph_break()\n\u001B[32m---> \u001B[39m\u001B[32m79\u001B[39m     ret = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     80\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torch/optim/adam.py:225\u001B[39m, in \u001B[36mAdam.step\u001B[39m\u001B[34m(self, closure)\u001B[39m\n\u001B[32m    224\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m torch.enable_grad():\n\u001B[32m--> \u001B[39m\u001B[32m225\u001B[39m         loss = \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    227\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.param_groups:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/plugins/precision/precision.py:109\u001B[39m, in \u001B[36mPrecision._wrap_closure\u001B[39m\u001B[34m(self, model, optimizer, closure)\u001B[39m\n\u001B[32m    102\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001B[39;00m\n\u001B[32m    103\u001B[39m \u001B[33;03mhook is called.\u001B[39;00m\n\u001B[32m    104\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    107\u001B[39m \n\u001B[32m    108\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m109\u001B[39m closure_result = \u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    110\u001B[39m \u001B[38;5;28mself\u001B[39m._after_closure(model, optimizer)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py:146\u001B[39m, in \u001B[36mClosure.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    144\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    145\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001B[32m--> \u001B[39m\u001B[32m146\u001B[39m     \u001B[38;5;28mself\u001B[39m._result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mclosure\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    147\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._result.loss\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:116\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    115\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py:131\u001B[39m, in \u001B[36mClosure.closure\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    128\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    129\u001B[39m \u001B[38;5;129m@torch\u001B[39m.enable_grad()\n\u001B[32m    130\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mclosure\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args: Any, **kwargs: Any) -> ClosureResult:\n\u001B[32m--> \u001B[39m\u001B[32m131\u001B[39m     step_output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_step_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    133\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m step_output.closure_loss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/loops/optimization/automatic.py:319\u001B[39m, in \u001B[36m_AutomaticOptimization._training_step\u001B[39m\u001B[34m(self, kwargs)\u001B[39m\n\u001B[32m    317\u001B[39m trainer = \u001B[38;5;28mself\u001B[39m.trainer\n\u001B[32m--> \u001B[39m\u001B[32m319\u001B[39m training_step_output = \u001B[43mcall\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_strategy_hook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtraining_step\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    320\u001B[39m \u001B[38;5;28mself\u001B[39m.trainer.strategy.post_training_step()  \u001B[38;5;66;03m# unused hook - call anyway for backward compatibility\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:328\u001B[39m, in \u001B[36m_call_strategy_hook\u001B[39m\u001B[34m(trainer, hook_name, *args, **kwargs)\u001B[39m\n\u001B[32m    327\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m trainer.profiler.profile(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m[Strategy]\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrainer.strategy.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhook_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m328\u001B[39m     output = \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    330\u001B[39m \u001B[38;5;66;03m# restore current_fx when nested context\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/strategies/strategy.py:391\u001B[39m, in \u001B[36mStrategy.training_step\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    390\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_redirection(\u001B[38;5;28mself\u001B[39m.model, \u001B[38;5;28mself\u001B[39m.lightning_module, \u001B[33m\"\u001B[39m\u001B[33mtraining_step\u001B[39m\u001B[33m\"\u001B[39m, *args, **kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m391\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlightning_module\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtraining_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 90\u001B[39m, in \u001B[36mFireFeatureExtractorViT.training_step\u001B[39m\u001B[34m(self, batch, batch_idx)\u001B[39m\n\u001B[32m     89\u001B[39m preds = torch.sigmoid(outputs) > \u001B[32m0.5\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrain_acc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Update accuracy metric\u001B[39;00m\n\u001B[32m     92\u001B[39m \u001B[38;5;66;03m# Log training metrics (step-level loss, epoch-level accuracy)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torchmetrics/metric.py:315\u001B[39m, in \u001B[36mMetric.forward\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    314\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m315\u001B[39m     \u001B[38;5;28mself\u001B[39m._forward_cache = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_forward_reduce_state_update\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    317\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_cache\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torchmetrics/metric.py:384\u001B[39m, in \u001B[36mMetric._forward_reduce_state_update\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    383\u001B[39m \u001B[38;5;66;03m# calculate batch state and compute batch value\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m384\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    385\u001B[39m batch_val = \u001B[38;5;28mself\u001B[39m.compute()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torchmetrics/metric.py:549\u001B[39m, in \u001B[36mMetric._wrap_update.<locals>.wrapped_func\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    548\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m549\u001B[39m     \u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    550\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torchmetrics/classification/stat_scores.py:187\u001B[39m, in \u001B[36mBinaryStatScores.update\u001B[39m\u001B[34m(self, preds, target)\u001B[39m\n\u001B[32m    186\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.validate_args:\n\u001B[32m--> \u001B[39m\u001B[32m187\u001B[39m     \u001B[43m_binary_stat_scores_tensor_validation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpreds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmultidim_average\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    188\u001B[39m preds, target = _binary_stat_scores_format(preds, target, \u001B[38;5;28mself\u001B[39m.threshold, \u001B[38;5;28mself\u001B[39m.ignore_index)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torchmetrics/functional/classification/stat_scores.py:71\u001B[39m, in \u001B[36m_binary_stat_scores_tensor_validation\u001B[39m\u001B[34m(preds, target, multidim_average, ignore_index)\u001B[39m\n\u001B[32m     70\u001B[39m \u001B[38;5;66;03m# Check that target only contains [0,1] values or value in ignore_index\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m71\u001B[39m unique_values = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43munique\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ignore_index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torch/_jit_internal.py:622\u001B[39m, in \u001B[36mboolean_dispatch.<locals>.fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    621\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m622\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mif_false\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torch/_jit_internal.py:622\u001B[39m, in \u001B[36mboolean_dispatch.<locals>.fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    621\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m622\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mif_false\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torch/functional.py:1102\u001B[39m, in \u001B[36m_return_output\u001B[39m\u001B[34m(input, sorted, return_inverse, return_counts, dim)\u001B[39m\n\u001B[32m   1100\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _unique_impl(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28msorted\u001B[39m, return_inverse, return_counts, dim)\n\u001B[32m-> \u001B[39m\u001B[32m1102\u001B[39m output, _, _ = \u001B[43m_unique_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43msorted\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_inverse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_counts\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1103\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/torch/functional.py:995\u001B[39m, in \u001B[36m_unique_impl\u001B[39m\u001B[34m(input, sorted, return_inverse, return_counts, dim)\u001B[39m\n\u001B[32m    994\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m995\u001B[39m     output, inverse_indices, counts = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_unique2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    996\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    997\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43msorted\u001B[39;49m\u001B[43m=\u001B[49m\u001B[38;5;28;43msorted\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    998\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_inverse\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_inverse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    999\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreturn_counts\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_counts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1000\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1001\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m output, inverse_indices, counts\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;66;03m# Step 1: Train the feature extractor model\u001B[39;00m\n\u001B[32m      9\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mTraining feature extractor...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m trained_model, trainer, data = \u001B[43mtrain_feature_extractor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m40\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# Step 2: Save the trained model for future use\u001B[39;00m\n\u001B[32m     13\u001B[39m save_feature_extractor(trainer, \u001B[33m\"\u001B[39m\u001B[33mSaved_Features/ViT_fire_feature_extractor.pth\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 60\u001B[39m, in \u001B[36mtrain_feature_extractor\u001B[39m\u001B[34m(num_epochs)\u001B[39m\n\u001B[32m     51\u001B[39m trainer = pl.Trainer(\n\u001B[32m     52\u001B[39m     max_epochs=num_epochs,    \u001B[38;5;66;03m# Training duration\u001B[39;00m\n\u001B[32m     53\u001B[39m     callbacks=[checkpoint],    \u001B[38;5;66;03m# Attach checkpoint callback\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     56\u001B[39m     log_every_n_steps=\u001B[32m10\u001B[39m,     \u001B[38;5;66;03m# Log metrics every 10 batches\u001B[39;00m\n\u001B[32m     57\u001B[39m )\n\u001B[32m     59\u001B[39m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m60\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     62\u001B[39m \u001B[38;5;66;03m# Evaluate on test set after training\u001B[39;00m\n\u001B[32m     63\u001B[39m test_result = trainer.test(model, dataloaders=data.test_dataloader())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/trainer.py:561\u001B[39m, in \u001B[36mTrainer.fit\u001B[39m\u001B[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001B[39m\n\u001B[32m    559\u001B[39m \u001B[38;5;28mself\u001B[39m.training = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    560\u001B[39m \u001B[38;5;28mself\u001B[39m.should_stop = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m561\u001B[39m \u001B[43mcall\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_call_and_handle_interrupt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    562\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fit_impl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_dataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdatamodule\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_path\u001B[49m\n\u001B[32m    563\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/call.py:65\u001B[39m, in \u001B[36m_call_and_handle_interrupt\u001B[39m\u001B[34m(trainer, trainer_fn, *args, **kwargs)\u001B[39m\n\u001B[32m     63\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(launcher, _SubprocessScriptLauncher):\n\u001B[32m     64\u001B[39m         launcher.kill(_get_sigkill_signal())\n\u001B[32m---> \u001B[39m\u001B[32m65\u001B[39m     \u001B[43mexit\u001B[49m(\u001B[32m1\u001B[39m)\n\u001B[32m     67\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exception:\n\u001B[32m     68\u001B[39m     _interrupt(trainer, exception)\n",
      "\u001B[31mNameError\u001B[39m: name 'exit' is not defined"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CNN Branch",
   "id": "5da7e78bdf6694e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset",
   "id": "df422fde74918d98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T23:31:55.495795Z",
     "start_time": "2025-07-31T23:31:55.479252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Custom Dataset Class for Processed Thermal Images\n",
    "class ProcessedThermalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for loading processed thermal images from directory structure.\n",
    "\n",
    "    Args:\n",
    "        root_dir: Root directory containing class subdirectories\n",
    "        transform: Composition of image transformations to apply\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
    "        self.classes = self.dataset.classes\n",
    "        self.class_to_idx = self.dataset.class_to_idx\n",
    "        self.samples = self.dataset.samples\n",
    "        self.targets = self.dataset.targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "# Data Module for Thermal Image Processing and Augmentation Saving\n",
    "class ThermalDataModule:\n",
    "    def __init__(self,\n",
    "                 raw_data_dir='dataset/raw/thermal',\n",
    "                 processed_dir='dataset/thermal_processed',\n",
    "                 train_augmented_multiplicity=4,\n",
    "                 batch_size=16,\n",
    "                 regenerate=False):\n",
    "        \"\"\"\n",
    "        Handles thermal data processing, augmentation, and saving.\n",
    "\n",
    "        Args:\n",
    "            raw_data_dir: Directory with 'fire' and 'no_fire' subdirectories\n",
    "            processed_dir: Where to save processed images\n",
    "            train_augmented_multiplicity: Number of augmented versions per training image\n",
    "            batch_size: Batch size for dataloaders\n",
    "            regenerate: Force regeneration of processed images\n",
    "        \"\"\"\n",
    "        self.raw_data_dir = raw_data_dir\n",
    "        self.processed_dir = processed_dir\n",
    "        self.train_augmented_multiplicity = train_augmented_multiplicity\n",
    "        self.batch_size = batch_size\n",
    "        self.regenerate = regenerate\n",
    "        self.classes = ['no_fire', 'fire']\n",
    "\n",
    "        # Define transforms - ensure output is 1-channel grayscale\n",
    "        self.augment_transform = v2.Compose([\n",
    "            v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
    "            v2.RandomHorizontalFlip(p=0.5),\n",
    "            v2.GaussianBlur(kernel_size=3, sigma=(0.5, 2.0)),\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "            v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "        ])\n",
    "\n",
    "        self.test_transform = v2.Compose([\n",
    "            v2.Resize(size=(224, 224), antialias=True),\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "            v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "        ])\n",
    "\n",
    "        # Loading transform (applied when loading saved images)\n",
    "        self.loading_transform = v2.Compose([\n",
    "            v2.Grayscale(num_output_channels=1),  # Ensure grayscale conversion\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Normalize(mean=[0.5], std=[0.5])\n",
    "        ])\n",
    "\n",
    "        # Create datasets after processing\n",
    "        self.setup()\n",
    "\n",
    "    def _denormalize(self, tensor):\n",
    "        \"\"\"Convert normalized tensor back to PIL Image\"\"\"\n",
    "        inverse_norm = v2.Normalize(\n",
    "            mean=[-0.5/0.5],\n",
    "            std=[1/0.5]\n",
    "        )\n",
    "        tensor = inverse_norm(tensor)\n",
    "        tensor = torch.clamp(tensor, 0, 1)\n",
    "        tensor = tensor.mul(255).byte()\n",
    "        return v2.ToPILImage()(tensor.cpu())\n",
    "\n",
    "    def _save_augmented_images(self):\n",
    "        \"\"\"Process and save augmented images to filesystem\"\"\"\n",
    "        fire_dir = os.path.join(self.raw_data_dir, 'fire')\n",
    "        non_fire_dir = os.path.join(self.raw_data_dir, 'no_fire')\n",
    "\n",
    "        # Collect image paths and labels\n",
    "        image_paths = []\n",
    "        labels = []\n",
    "\n",
    "        # Load fire images (label=1)\n",
    "        if os.path.isdir(fire_dir):\n",
    "            for filename in os.listdir(fire_dir):\n",
    "                if filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    image_paths.append(os.path.join(fire_dir, filename))\n",
    "                    labels.append(1)\n",
    "\n",
    "        # Load non-fire images (label=0)\n",
    "        if os.path.isdir(non_fire_dir):\n",
    "            for filename in os.listdir(non_fire_dir):\n",
    "                if filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    image_paths.append(os.path.join(non_fire_dir, filename))\n",
    "                    labels.append(0)\n",
    "\n",
    "        if not image_paths:\n",
    "            raise ValueError(\"No images found in raw data directories\")\n",
    "\n",
    "        # Print raw class distribution\n",
    "        print(\"\\nRaw Data Class Distribution:\")\n",
    "        print(f\"Total images: {len(image_paths)}\")\n",
    "        print(f\"Fire images: {labels.count(1)} ({labels.count(1)/len(labels):.1%})\")\n",
    "        print(f\"No-fire images: {labels.count(0)} ({labels.count(0)/len(labels):.1%})\")\n",
    "\n",
    "        # Verify we have both classes\n",
    "        if labels.count(1) == 0 or labels.count(0) == 0:\n",
    "            raise ValueError(\"Dataset missing one class! Cannot perform stratified split\")\n",
    "\n",
    "        # Create 70/15/15 split with no overlapping images\n",
    "        # Step 1: Split into train (70%) and temp (30%)\n",
    "        train_img, temp_img, train_lbl, temp_lbl = train_test_split(\n",
    "            image_paths, labels,\n",
    "            test_size=0.3,\n",
    "            random_state=42,\n",
    "            stratify=labels\n",
    "        )\n",
    "\n",
    "        # Step 2: Split temp into val (15%) and test (15%)\n",
    "        val_img, test_img, val_lbl, test_lbl = train_test_split(\n",
    "            temp_img, temp_lbl,\n",
    "            test_size=0.5,\n",
    "            random_state=42,\n",
    "            stratify=temp_lbl\n",
    "        )\n",
    "\n",
    "        # Create directory structure\n",
    "        splits = {\n",
    "            'train': (train_img, train_lbl, self.train_augmented_multiplicity),\n",
    "            'val': (val_img, val_lbl, 1),\n",
    "            'test': (test_img, test_lbl, 1)\n",
    "        }\n",
    "\n",
    "        # Verify no overlapping images\n",
    "        train_set = set(train_img)\n",
    "        val_set = set(val_img)\n",
    "        test_set = set(test_img)\n",
    "\n",
    "        assert train_set.isdisjoint(val_set), \"Train and validation sets overlap!\"\n",
    "        assert train_set.isdisjoint(test_set), \"Train and test sets overlap!\"\n",
    "        assert val_set.isdisjoint(test_set), \"Validation and test sets overlap!\"\n",
    "\n",
    "        # Print distribution statistics\n",
    "        print(\"\\nDataset Split Distribution:\")\n",
    "        print(f\"Total images: {len(image_paths)}\")\n",
    "        print(f\"Training images: {len(train_img)} ({len(train_img)/len(image_paths):.1%})\")\n",
    "        print(f\"Validation images: {len(val_img)} ({len(val_img)/len(image_paths):.1%})\")\n",
    "        print(f\"Test images: {len(test_img)} ({len(test_img)/len(image_paths):.1%})\")\n",
    "\n",
    "        print(\"\\nClass Distribution in Splits:\")\n",
    "        print(\"Training - Fire:\", train_lbl.count(1), f\"({train_lbl.count(1)/len(train_lbl):.1%})\",\n",
    "              \"No Fire:\", train_lbl.count(0), f\"({train_lbl.count(0)/len(train_lbl):.1%})\")\n",
    "        print(\"Validation - Fire:\", val_lbl.count(1), f\"({val_lbl.count(1)/len(val_lbl):.1%})\",\n",
    "              \"No Fire:\", val_lbl.count(0), f\"({val_lbl.count(0)/len(val_lbl):.1%})\")\n",
    "        print(\"Test - Fire:\", test_lbl.count(1), f\"({test_lbl.count(1)/len(test_lbl):.1%})\",\n",
    "              \"No Fire:\", test_lbl.count(0), f\"({test_lbl.count(0)/len(test_lbl):.1%})\")\n",
    "\n",
    "        # CRITICAL: Ensure validation set has fire images\n",
    "        if val_lbl.count(1) == 0:\n",
    "            raise RuntimeError(\"Validation set has ZERO fire images! Check data distribution\")\n",
    "\n",
    "        for split_name, (img_paths, lbls, multiplicity) in splits.items():\n",
    "            split_dir = os.path.join(self.processed_dir, split_name)\n",
    "            for class_name in self.classes:\n",
    "                class_dir = os.path.join(split_dir, class_name)\n",
    "                os.makedirs(class_dir, exist_ok=True)\n",
    "\n",
    "            for img_path, label in zip(img_paths, lbls):\n",
    "                img = Image.open(img_path)\n",
    "                # Convert to RGB first to ensure consistent processing\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                class_name = self.classes[label]\n",
    "\n",
    "                for aug_idx in range(multiplicity):\n",
    "                    # Apply transforms\n",
    "                    if split_name == 'train':\n",
    "                        transformed = self.augment_transform(img)\n",
    "                    else:\n",
    "                        transformed = self.test_transform(img)\n",
    "\n",
    "                    # Convert back to PIL and save\n",
    "                    img_pil = self._denormalize(transformed)\n",
    "                    fname = os.path.basename(img_path)\n",
    "                    base, ext = os.path.splitext(fname)\n",
    "                    save_path = os.path.join(\n",
    "                        split_dir,\n",
    "                        class_name,\n",
    "                        f\"{base}_aug{aug_idx}{ext}\"\n",
    "                    )\n",
    "                    img_pil.save(save_path)\n",
    "\n",
    "        print(\"Augmented dataset saved successfully!\")\n",
    "\n",
    "    def setup(self):\n",
    "        \"\"\"Prepare datasets by processing and saving images if needed\"\"\"\n",
    "        # Regenerate images if requested or not exists\n",
    "        if self.regenerate or not os.path.exists(self.processed_dir):\n",
    "            print(\"Generating and saving augmented dataset...\")\n",
    "            self._save_augmented_images()\n",
    "\n",
    "        # Create datasets from saved images\n",
    "        self.train_dataset = ProcessedThermalDataset(\n",
    "            os.path.join(self.processed_dir, 'train'),\n",
    "            transform=self.loading_transform\n",
    "        )\n",
    "        self.val_dataset = ProcessedThermalDataset(\n",
    "            os.path.join(self.processed_dir, 'val'),\n",
    "            transform=self.loading_transform\n",
    "        )\n",
    "        self.test_dataset = ProcessedThermalDataset(\n",
    "            os.path.join(self.processed_dir, 'test'),\n",
    "            transform=self.loading_transform\n",
    "        )\n",
    "\n",
    "        # Verify image channels\n",
    "        img, label = self.train_dataset[0]\n",
    "        print(f\"\\nFirst training image shape: {img.shape}\")\n",
    "        print(f\"First training label: {label} ({self.classes[label]})\")\n",
    "\n",
    "        # Verify validation set content\n",
    "        val_img, val_label = self.val_dataset[0]\n",
    "        print(f\"First validation image shape: {val_img.shape}\")\n",
    "        print(f\"First validation label: {val_label} ({self.classes[val_label]})\")\n",
    "\n",
    "        # Print class distribution in validation set\n",
    "        val_labels = [label for _, label in self.val_dataset]\n",
    "        print(f\"\\nValidation Set Class Distribution:\")\n",
    "        print(f\"Fire images: {sum(1 for l in val_labels if l == 1)}\")\n",
    "        print(f\"No-fire images: {sum(1 for l in val_labels if l == 0)}\")\n",
    "\n",
    "        # Create dataloaders\n",
    "        self.train_dataloaderCNN = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True\n",
    "        )\n",
    "        self.val_dataloaderCNN = DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "        self.test_dataloaderCNN = DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        # Print dataset stats\n",
    "        print(f\"\\nFinal Dataset Sizes:\")\n",
    "        print(f\" - Training: {len(self.train_dataset)} samples\")\n",
    "        print(f\" - Validation: {len(self.val_dataset)} samples\")\n",
    "        print(f\" - Testing: {len(self.test_dataset)} samples\")\n",
    "        print(f\" - Classes: {self.train_dataset.classes}\")"
   ],
   "id": "33ac7de58cc05418",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CNN Model",
   "id": "29add8cf6d62df53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:34:14.454592Z",
     "start_time": "2025-08-02T14:34:14.449861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FireFeatureExtractorCNN(nn.Module):\n",
    "    def __init__(self, feature_dim=1280):\n",
    "        super(FireFeatureExtractorCNN, self).__init__()\n",
    "        self.base_model = models.mobilenet_v2(weights='IMAGENET1K_V1')\n",
    "\n",
    "        # Modify first convolution layer for grayscale input\n",
    "        original_first_conv = self.base_model.features[0][0]\n",
    "        self.base_model.features[0][0] = nn.Conv2d(\n",
    "            1,  # Single channel input (thermal images)\n",
    "            original_first_conv.out_channels,\n",
    "            kernel_size=original_first_conv.kernel_size,\n",
    "            stride=original_first_conv.stride,\n",
    "            padding=original_first_conv.padding,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        # Initialize with averaged weights\n",
    "        with torch.no_grad():\n",
    "            # Average across RGB channels: [out, 3, k, k] -> [out, 1, k, k]\n",
    "            new_weight = original_first_conv.weight.mean(dim=1, keepdim=True)\n",
    "            self.base_model.features[0][0].weight.copy_(new_weight)\n",
    "\n",
    "        self.features = self.base_model.features\n",
    "        self.feature_processor = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.feature_refiner = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.classifier = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        # Ensure input is grayscale (1 channel)\n",
    "        if x.shape[1] == 3:\n",
    "            # Convert to grayscale using weighted average\n",
    "            x = 0.2989 * x[:, 0] + 0.5870 * x[:, 1] + 0.1140 * x[:, 2]\n",
    "            x = x.unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "        x = self.features(x)\n",
    "        x = self.feature_processor(x)\n",
    "        features = self.feature_refiner(x)\n",
    "        logits = self.classifier(features)\n",
    "\n",
    "        if return_features:\n",
    "            return logits, features\n",
    "        return logits\n"
   ],
   "id": "db7cc07a7fb4c8f3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "394a2a8ac03b7ad3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T23:31:28.331950Z",
     "start_time": "2025-07-31T23:31:28.311245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_model(model, train_dataloader, val_dataloader, num_epochs=10, lr=0.001):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    print(f\"Training on: {device}\")\n",
    "\n",
    "    # Calculate class weights for imbalance\n",
    "    train_targets = train_dataloader.dataset.targets\n",
    "    class_counts = [np.sum(np.array(train_targets) == 0),  # no_fire\n",
    "                   np.sum(np.array(train_targets) == 1)]   # fire\n",
    "\n",
    "    print(f\"\\nTraining Set Class Distribution:\")\n",
    "    print(f\" - No-fire: {class_counts[0]} samples ({class_counts[0]/len(train_targets):.1%})\")\n",
    "    print(f\" - Fire: {class_counts[1]} samples ({class_counts[1]/len(train_targets):.1%})\")\n",
    "\n",
    "    # Calculate pos_weight for BCEWithLogitsLoss\n",
    "    if class_counts[1] > 0:  # Prevent division by zero\n",
    "        pos_weight = torch.tensor([class_counts[0] / class_counts[1]]).to(device)\n",
    "    else:\n",
    "        pos_weight = torch.tensor([1.0]).to(device)\n",
    "        print(\"Warning: No fire samples in training set!\")\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    print(f\"Using positive weight: {pos_weight.item():.2f} for fire class\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Add learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='max',  # Monitor validation accuracy\n",
    "        factor=0.5,\n",
    "        patience=3\n",
    "    )\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "\n",
    "    # Diagnostic: Check first batch performance\n",
    "    print(\"\\nRunning diagnostic on first batch...\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        first_batch = next(iter(train_dataloader))\n",
    "        images, labels = first_batch\n",
    "        images, labels = images.to(device), labels.to(device).float()\n",
    "\n",
    "        print(f\"First batch image shape: {images.shape}\")\n",
    "        print(f\"First 5 labels: {labels[:5].cpu().numpy()}\")\n",
    "\n",
    "        outputs = model(images)\n",
    "        initial_loss = criterion(outputs.squeeze(), labels)\n",
    "        preds = torch.sigmoid(outputs) > 0.5\n",
    "        initial_acc = (preds.squeeze() == labels).float().mean()\n",
    "\n",
    "        print(f\"Initial loss (before training): {initial_loss.item():.4f}\")\n",
    "        print(f\"Initial accuracy (before training): {initial_acc.item():.4f}\")\n",
    "        print(f\"First 5 predictions: {preds[:5].squeeze().cpu().numpy()}\")\n",
    "\n",
    "    # Add gradient clipping\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping to prevent exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Calculate training accuracy\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            correct += (preds.squeeze() == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            train_acc = correct / total\n",
    "\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': loss.item(),\n",
    "                'acc': train_acc\n",
    "            })\n",
    "\n",
    "            # Log first batch of first epoch in detail\n",
    "            if epoch == 0 and batch_idx == 0:\n",
    "                print(\"\\nDetailed first batch analysis:\")\n",
    "                print(f\"Labels: {labels[:10].cpu().numpy()}\")\n",
    "                print(f\"Raw outputs: {outputs[:10].squeeze().detach().cpu().numpy()}\")\n",
    "                print(f\"Predictions: {preds[:10].squeeze().cpu().numpy()}\")\n",
    "\n",
    "                # Check model parameters\n",
    "                print(\"\\nModel parameter checks:\")\n",
    "                for name, param in model.named_parameters():\n",
    "                    if param.requires_grad and \"classifier\" not in name:\n",
    "                        print(f\"{name}: mean={param.data.mean().item():.6f}, std={param.data.std().item():.6f}\")\n",
    "                        if param.grad is not None:\n",
    "                            print(f\"  grad: mean={param.grad.mean().item():.6f}, std={param.grad.std().item():.6f}\")\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        epoch_train_acc = correct / total\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_acc = validate_model(model, val_dataloader, criterion, device)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        # Update learning rate based on validation accuracy\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"New best model with val_acc: {val_acc:.4f}\")\n",
    "\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs} Summary:')\n",
    "        print(f' - Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_train_acc:.4f}')\n",
    "        print(f' - Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "        print(f' - LR: {optimizer.param_groups[0][\"lr\"]:.2e}')\n",
    "\n",
    "        # Early stopping if validation accuracy is perfect\n",
    "        if val_acc >= 1.0 and epoch > 0:\n",
    "            print(\"Warning: Perfect validation accuracy detected. Stopping early for investigation.\")\n",
    "            break\n",
    "\n",
    "    # Plotting and saving\n",
    "    plot_training_history(train_losses, val_losses, val_accuracies)\n",
    "    torch.save(best_model_state, 'Saved_Features/CNN_best_model_weights.pth')\n",
    "    print(\"Saved best model weights to 'Saved_Features/CNN_best_model_weights.pth'\")\n",
    "\n",
    "    # Load best weights into model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    else:\n",
    "        print(\"Warning: No best model state found. Using final epoch model.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def validate_model(model, val_dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    fire_correct = 0\n",
    "    fire_total = 0\n",
    "    nofire_correct = 0\n",
    "    nofire_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "\n",
    "            # Track class-wise accuracy\n",
    "            for i in range(len(labels)):\n",
    "                if labels[i] == 1:\n",
    "                    fire_total += 1\n",
    "                    fire_correct += int(preds[i].item() == labels[i].item())\n",
    "                else:\n",
    "                    nofire_total += 1\n",
    "                    nofire_correct += int(preds[i].item() == labels[i].item())\n",
    "\n",
    "            correct += (preds.squeeze() == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Store for analysis - convert to flat arrays\n",
    "            all_preds.append(preds.cpu().numpy().flatten())\n",
    "            all_labels.append(labels.cpu().numpy().flatten())\n",
    "\n",
    "    if total == 0:\n",
    "        return 0, 0  # Prevent division by zero\n",
    "\n",
    "    val_loss = running_loss / total\n",
    "    val_acc = correct / total\n",
    "\n",
    "    # Print detailed report\n",
    "    print(\"\\nValidation Set Analysis:\")\n",
    "    print(f\"Total samples: {total}\")\n",
    "    print(f\"Fire samples: {fire_total} ({fire_total/total:.1%})\")\n",
    "    print(f\"No-fire samples: {nofire_total} ({nofire_total/total:.1%})\")\n",
    "    print(f\"Fire accuracy: {fire_correct/max(1, fire_total):.1%} ({fire_correct}/{fire_total})\")\n",
    "    print(f\"No-fire accuracy: {nofire_correct/max(1, nofire_total):.1%} ({nofire_correct}/{nofire_total})\")\n",
    "\n",
    "    # Combine all batches into single arrays\n",
    "    if all_preds:\n",
    "        all_preds_flat = np.concatenate(all_preds)\n",
    "        all_labels_flat = np.concatenate(all_labels)\n",
    "    else:\n",
    "        all_preds_flat = np.array([])\n",
    "        all_labels_flat = np.array([])\n",
    "\n",
    "    # Print prediction distribution\n",
    "    if len(all_preds_flat) > 0:\n",
    "        print(f\"Prediction distribution: {np.mean(all_preds_flat):.1%} fire predictions\")\n",
    "\n",
    "        # Print first 10 actual predictions\n",
    "        print(\"\\nFirst 10 validation predictions:\")\n",
    "        for i in range(min(10, len(all_preds_flat))):\n",
    "            pred = all_preds_flat[i]\n",
    "            label = all_labels_flat[i]\n",
    "            status = \"✅\" if pred == label else \"❌\"\n",
    "            print(f\"{status} Sample {i+1}: Predicted {'Fire' if pred else 'No-fire'}, Actual {'Fire' if label else 'No-fire'}\")\n",
    "\n",
    "    return val_loss, val_acc\n",
    "\n",
    "def test_model(model, test_dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images, labels = images.to(device), labels.to(device).float()\n",
    "            outputs, features = model(images, return_features=True)\n",
    "\n",
    "            all_features.append(features.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            correct += (preds.squeeze() == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    test_acc = correct / total\n",
    "    all_features = np.concatenate(all_features)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "    return test_acc, all_features, all_labels\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, val_accuracies):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_accuracies, label='Val Accuracy', color='green')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    os.makedirs('Figures', exist_ok=True)\n",
    "    plt.savefig('Figures/CNN_training_history.png')\n",
    "    plt.close()\n",
    "    print(\"Saved training history plot to 'Figures/CNN_training_history.png'\")\n",
    "\n",
    "def save_feature_extractor_cnn(model, path=\"Saved_Features/CNN_feature_extractor.pth\"):\n",
    "    state_dict = model.state_dict()\n",
    "    keys_to_remove = [k for k in state_dict.keys() if k.startswith('classifier')]\n",
    "    for k in keys_to_remove:\n",
    "        del state_dict[k]\n",
    "    torch.save(state_dict, path)\n",
    "    print(f\"CNN feature extractor saved to {path} (without classifier)\")"
   ],
   "id": "bcca91271a81f6e2",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T23:32:56.339727Z",
     "start_time": "2025-07-31T23:32:04.959447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- FEATURE EXTRACTOR TRAINING PIPELINE ---\n",
    "# Clear GPU memory cache to prevent out-of-memory errors\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Start performance timer\n",
    "start = time.time()\n",
    "\n",
    "# Initialize data module with augmentation saving\n",
    "print(\"Processing thermal data and saving augmented images...\")\n",
    "data_module = ThermalDataModule(\n",
    "    raw_data_dir='dataset/raw/thermal',\n",
    "    processed_dir='dataset/thermal_processed',\n",
    "    train_augmented_multiplicity=4,\n",
    "    batch_size=16,\n",
    "    regenerate=True  # Set to True to recreate dataset\n",
    ")\n",
    "\n",
    "# Step 1: Initialize the CNN-based feature extractor model\n",
    "print(\"Initializing feature extractor model...\")\n",
    "model = FireFeatureExtractorCNN()\n",
    "\n",
    "# Step 2: Train the model\n",
    "print(\"\\nStarting model training...\")\n",
    "trained_model = train_model(\n",
    "    model,\n",
    "    data_module.train_dataloaderCNN,\n",
    "    data_module.val_dataloaderCNN,\n",
    "    num_epochs=15,\n",
    "    lr=0.0001\n",
    ")\n",
    "\n",
    "# Step 3: Evaluate on test set and extract features\n",
    "print(\"\\nEvaluating model on test set...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_acc, test_features, test_labels = test_model(\n",
    "    trained_model,\n",
    "    data_module.test_dataloaderCNN,\n",
    "    device\n",
    ")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Step 4: Save feature extractor without classification head\n",
    "print(\"\\nSaving feature extractor weights...\")\n",
    "save_feature_extractor_cnn(trained_model, \"Saved_Features/CNN_fire_feature_extractor.pth\")\n",
    "\n",
    "# Step 5: Analyze extracted features\n",
    "print(\"\\nFeature Extraction Summary:\")\n",
    "print(f\"Extracted {len(test_features)} feature vectors\")\n",
    "print(f\"Feature vector shape: {test_features[0].shape}\")\n",
    "print(\"Sample feature (first 10 values):\", test_features[0][:10])\n",
    "print(\"...\")\n",
    "\n",
    "# Step 6: Save features for downstream multi-model system\n",
    "print(\"\\nSaving features for ensemble model training...\")\n",
    "os.makedirs('Saved_Features', exist_ok=True)\n",
    "np.save('Saved_Features/CNN_test_features.npy', test_features)\n",
    "np.save('Saved_Features/CNN_test_labels.npy', test_labels)\n",
    "print(\"Features and labels saved in Saved_Features/ directory\")\n",
    "\n",
    "# Calculate and display execution time\n",
    "time_taken = time.time() - start\n",
    "print(f\"\\nTotal Execution Time: {time_taken:.2f} seconds ({time_taken / 60:.2f} minutes)\")"
   ],
   "id": "5329349b55e4280f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing thermal data and saving augmented images...\n",
      "Generating and saving augmented dataset...\n",
      "\n",
      "Raw Data Class Distribution:\n",
      "Total images: 533\n",
      "Fire images: 417 (78.2%)\n",
      "No-fire images: 116 (21.8%)\n",
      "\n",
      "📊 Dataset Split Distribution:\n",
      "Total images: 533\n",
      "Training images: 373 (70.0%)\n",
      "Validation images: 80 (15.0%)\n",
      "Test images: 80 (15.0%)\n",
      "\n",
      "Class Distribution in Splits:\n",
      "Training - Fire: 292 (78.3%) No Fire: 81 (21.7%)\n",
      "Validation - Fire: 63 (78.8%) No Fire: 17 (21.2%)\n",
      "Test - Fire: 62 (77.5%) No Fire: 18 (22.5%)\n",
      "Augmented dataset saved successfully!\n",
      "\n",
      "First training image shape: torch.Size([1, 224, 224])\n",
      "First training label: 0 (no_fire)\n",
      "First validation image shape: torch.Size([1, 224, 224])\n",
      "First validation label: 0 (no_fire)\n",
      "\n",
      "Validation Set Class Distribution:\n",
      "Fire images: 17\n",
      "No-fire images: 63\n",
      "\n",
      "Final Dataset Sizes:\n",
      " - Training: 1492 samples\n",
      " - Validation: 80 samples\n",
      " - Testing: 80 samples\n",
      " - Classes: ['fire', 'no_fire']\n",
      "Initializing feature extractor model...\n",
      "\n",
      "Starting model training...\n",
      "Training on: cuda\n",
      "\n",
      "Training Set Class Distribution:\n",
      " - No-fire: 1168 samples (78.3%)\n",
      " - Fire: 324 samples (21.7%)\n",
      "Using positive weight: 3.60 for fire class\n",
      "\n",
      "Running diagnostic on first batch...\n",
      "First batch image shape: torch.Size([16, 1, 224, 224])\n",
      "First 5 labels: [1. 0. 0. 0. 0.]\n",
      "Initial loss (before training): 0.9073\n",
      "Initial accuracy (before training): 0.8750\n",
      "First 5 predictions: [False False False False False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]:   1%|          | 1/94 [00:00<00:32,  2.85it/s, loss=1.15, acc=0.688]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed first batch analysis:\n",
      "Labels: [1. 0. 1. 0. 1. 0. 1. 0. 0. 0.]\n",
      "Raw outputs: [ 0.13272625 -0.0490072  -0.04258956 -0.000714   -0.04495082 -0.00431211\n",
      " -0.1083767  -0.09835131  0.15155178 -0.02629899]\n",
      "Predictions: [ True False False False False False False False  True False]\n",
      "\n",
      "Model parameter checks:\n",
      "base_model.features.0.0.weight: mean=-0.000880, std=0.178995\n",
      "  grad: mean=-0.009961, std=0.048500\n",
      "base_model.features.0.1.weight: mean=0.198515, std=0.151526\n",
      "  grad: mean=-0.001921, std=0.006943\n",
      "base_model.features.0.1.bias: mean=0.218089, std=0.378694\n",
      "  grad: mean=-0.002319, std=0.007581\n",
      "base_model.features.1.conv.0.0.weight: mean=0.006950, std=0.476703\n",
      "  grad: mean=-0.001690, std=0.011335\n",
      "base_model.features.1.conv.0.1.weight: mean=0.365765, std=0.329835\n",
      "  grad: mean=-0.000266, std=0.007158\n",
      "base_model.features.1.conv.0.1.bias: mean=0.446404, std=0.554804\n",
      "  grad: mean=-0.000553, std=0.001503\n",
      "base_model.features.1.conv.1.weight: mean=0.005115, std=0.222593\n",
      "  grad: mean=0.000286, std=0.004333\n",
      "base_model.features.1.conv.2.weight: mean=0.553152, std=0.071564\n",
      "  grad: mean=0.000288, std=0.008935\n",
      "base_model.features.1.conv.2.bias: mean=-0.000017, std=0.000053\n",
      "  grad: mean=0.000000, std=0.000000\n",
      "base_model.features.2.conv.0.0.weight: mean=0.000072, std=0.172238\n",
      "  grad: mean=-0.000000, std=0.002415\n",
      "base_model.features.2.conv.0.1.weight: mean=0.253842, std=0.146783\n",
      "  grad: mean=-0.000058, std=0.001932\n",
      "base_model.features.2.conv.0.1.bias: mean=0.121884, std=0.157452\n",
      "  grad: mean=0.000352, std=0.003028\n",
      "base_model.features.2.conv.1.0.weight: mean=-0.007211, std=0.160154\n",
      "  grad: mean=0.000100, std=0.002105\n",
      "base_model.features.2.conv.1.1.weight: mean=0.320161, std=0.120399\n",
      "  grad: mean=0.000118, std=0.004072\n",
      "base_model.features.2.conv.1.1.bias: mean=0.137897, std=0.256332\n",
      "  grad: mean=0.000148, std=0.001940\n",
      "base_model.features.2.conv.2.weight: mean=0.003213, std=0.161294\n",
      "  grad: mean=-0.000003, std=0.001393\n",
      "base_model.features.2.conv.3.weight: mean=0.493702, std=0.091665\n",
      "  grad: mean=0.000120, std=0.003015\n",
      "base_model.features.2.conv.3.bias: mean=0.000002, std=0.000020\n",
      "  grad: mean=-0.000000, std=0.000000\n",
      "base_model.features.3.conv.0.0.weight: mean=0.003756, std=0.116693\n",
      "  grad: mean=-0.000000, std=0.000949\n",
      "base_model.features.3.conv.0.1.weight: mean=0.174649, std=0.066038\n",
      "  grad: mean=0.000131, std=0.001257\n",
      "base_model.features.3.conv.0.1.bias: mean=0.107171, std=0.155866\n",
      "  grad: mean=-0.000171, std=0.001208\n",
      "base_model.features.3.conv.1.0.weight: mean=0.002371, std=0.184935\n",
      "  grad: mean=0.000251, std=0.001162\n",
      "base_model.features.3.conv.1.1.weight: mean=0.246692, std=0.061398\n",
      "  grad: mean=-0.000048, std=0.001852\n",
      "base_model.features.3.conv.1.1.bias: mean=0.073524, std=0.181444\n",
      "  grad: mean=-0.000045, std=0.000950\n",
      "base_model.features.3.conv.2.weight: mean=0.005114, std=0.116444\n",
      "  grad: mean=-0.000036, std=0.000800\n",
      "base_model.features.3.conv.3.weight: mean=0.551197, std=0.096000\n",
      "  grad: mean=-0.000180, std=0.002375\n",
      "base_model.features.3.conv.3.bias: mean=0.000001, std=0.000009\n",
      "  grad: mean=-0.000000, std=0.000000\n",
      "base_model.features.4.conv.0.0.weight: mean=-0.002344, std=0.149290\n",
      "  grad: mean=-0.000001, std=0.000959\n",
      "base_model.features.4.conv.0.1.weight: mean=0.229794, std=0.084307\n",
      "  grad: mean=0.000045, std=0.001247\n",
      "base_model.features.4.conv.0.1.bias: mean=0.040254, std=0.141345\n",
      "  grad: mean=-0.000026, std=0.001900\n",
      "base_model.features.4.conv.1.0.weight: mean=0.013193, std=0.120081\n",
      "  grad: mean=0.000019, std=0.000830\n",
      "base_model.features.4.conv.1.1.weight: mean=0.284974, std=0.079539\n",
      "  grad: mean=0.000070, std=0.002307\n",
      "base_model.features.4.conv.1.1.bias: mean=0.166801, std=0.197516\n",
      "  grad: mean=-0.000015, std=0.000823\n",
      "base_model.features.4.conv.2.weight: mean=0.000572, std=0.134448\n",
      "  grad: mean=-0.000010, std=0.000801\n",
      "base_model.features.4.conv.3.weight: mean=0.576053, std=0.078499\n",
      "  grad: mean=-0.000062, std=0.002364\n",
      "base_model.features.4.conv.3.bias: mean=0.000003, std=0.000006\n",
      "  grad: mean=-0.000000, std=0.000000\n",
      "base_model.features.5.conv.0.0.weight: mean=-0.000317, std=0.087419\n",
      "  grad: mean=-0.000031, std=0.000611\n",
      "base_model.features.5.conv.0.1.weight: mean=0.125764, std=0.039605\n",
      "  grad: mean=-0.000131, std=0.001350\n",
      "base_model.features.5.conv.0.1.bias: mean=0.120796, std=0.108895\n",
      "  grad: mean=0.000103, std=0.000903\n",
      "base_model.features.5.conv.1.0.weight: mean=-0.003648, std=0.141042\n",
      "  grad: mean=-0.000041, std=0.000917\n",
      "base_model.features.5.conv.1.1.weight: mean=0.215403, std=0.061301\n",
      "  grad: mean=0.000011, std=0.001349\n",
      "base_model.features.5.conv.1.1.bias: mean=-0.010715, std=0.145657\n",
      "  grad: mean=0.000068, std=0.000836\n",
      "base_model.features.5.conv.2.weight: mean=0.000617, std=0.085869\n",
      "  grad: mean=0.000002, std=0.000521\n",
      "base_model.features.5.conv.3.weight: mean=0.344094, std=0.097509\n",
      "  grad: mean=0.000397, std=0.002186\n",
      "base_model.features.5.conv.3.bias: mean=-0.000000, std=0.000005\n",
      "  grad: mean=0.000000, std=0.000000\n",
      "base_model.features.6.conv.0.0.weight: mean=-0.000495, std=0.083312\n",
      "  grad: mean=0.000006, std=0.000510\n",
      "base_model.features.6.conv.0.1.weight: mean=0.124748, std=0.033570\n",
      "  grad: mean=0.000004, std=0.000808\n",
      "base_model.features.6.conv.0.1.bias: mean=0.081085, std=0.091067\n",
      "  grad: mean=0.000050, std=0.000652\n",
      "base_model.features.6.conv.1.0.weight: mean=-0.002689, std=0.118560\n",
      "  grad: mean=0.000023, std=0.000739\n",
      "base_model.features.6.conv.1.1.weight: mean=0.203975, std=0.056481\n",
      "  grad: mean=0.000013, std=0.001407\n",
      "base_model.features.6.conv.1.1.bias: mean=-0.031644, std=0.155981\n",
      "  grad: mean=-0.000034, std=0.000786\n",
      "base_model.features.6.conv.2.weight: mean=-0.000548, std=0.080238\n",
      "  grad: mean=0.000010, std=0.000463\n",
      "base_model.features.6.conv.3.weight: mean=0.315683, std=0.074110\n",
      "  grad: mean=-0.000617, std=0.001815\n",
      "base_model.features.6.conv.3.bias: mean=-0.000000, std=0.000004\n",
      "  grad: mean=0.000000, std=0.000000\n",
      "base_model.features.7.conv.0.0.weight: mean=-0.003627, std=0.127962\n",
      "  grad: mean=0.000017, std=0.000699\n",
      "base_model.features.7.conv.0.1.weight: mean=0.186451, std=0.057878\n",
      "  grad: mean=-0.000036, std=0.001141\n",
      "base_model.features.7.conv.0.1.bias: mean=0.046649, std=0.122149\n",
      "  grad: mean=0.000061, std=0.001127\n",
      "base_model.features.7.conv.1.0.weight: mean=0.006209, std=0.111146\n",
      "  grad: mean=-0.000024, std=0.000732\n",
      "base_model.features.7.conv.1.1.weight: mean=0.222643, std=0.042281\n",
      "  grad: mean=-0.000045, std=0.002024\n",
      "base_model.features.7.conv.1.1.bias: mean=0.237352, std=0.172344\n",
      "  grad: mean=0.000043, std=0.000655\n",
      "base_model.features.7.conv.2.weight: mean=0.000437, std=0.101959\n",
      "  grad: mean=0.000002, std=0.000556\n",
      "base_model.features.7.conv.3.weight: mean=0.479989, std=0.072751\n",
      "  grad: mean=-0.000145, std=0.002055\n",
      "base_model.features.7.conv.3.bias: mean=-0.000000, std=0.000005\n",
      "  grad: mean=0.000000, std=0.000000\n",
      "base_model.features.8.conv.0.0.weight: mean=-0.000183, std=0.057081\n",
      "  grad: mean=-0.000009, std=0.000428\n",
      "base_model.features.8.conv.0.1.weight: mean=0.105207, std=0.023607\n",
      "  grad: mean=0.000022, std=0.001118\n",
      "base_model.features.8.conv.0.1.bias: mean=0.096630, std=0.081549\n",
      "  grad: mean=-0.000010, std=0.000776\n",
      "base_model.features.8.conv.1.0.weight: mean=-0.004063, std=0.107968\n",
      "  grad: mean=-0.000016, std=0.000909\n",
      "base_model.features.8.conv.1.1.weight: mean=0.184462, std=0.044874\n",
      "  grad: mean=0.000002, std=0.001152\n",
      "base_model.features.8.conv.1.1.bias: mean=-0.012297, std=0.090572\n",
      "  grad: mean=-0.000007, std=0.000789\n",
      "base_model.features.8.conv.2.weight: mean=-0.000447, std=0.056980\n",
      "  grad: mean=-0.000001, std=0.000426\n",
      "base_model.features.8.conv.3.weight: mean=0.305227, std=0.086122\n",
      "  grad: mean=0.000274, std=0.002103\n",
      "base_model.features.8.conv.3.bias: mean=-0.000001, std=0.000004\n",
      "  grad: mean=0.000000, std=0.000000\n",
      "base_model.features.9.conv.0.0.weight: mean=0.000198, std=0.056769\n",
      "  grad: mean=0.000001, std=0.000466\n",
      "base_model.features.9.conv.0.1.weight: mean=0.106255, std=0.027703\n",
      "  grad: mean=-0.000100, std=0.000999\n",
      "base_model.features.9.conv.0.1.bias: mean=0.053204, std=0.070764\n",
      "  grad: mean=0.000096, std=0.000869\n",
      "base_model.features.9.conv.1.0.weight: mean=-0.001610, std=0.089230\n",
      "  grad: mean=-0.000018, std=0.000861\n",
      "base_model.features.9.conv.1.1.weight: mean=0.171625, std=0.045900\n",
      "  grad: mean=0.000010, std=0.001228\n",
      "base_model.features.9.conv.1.1.bias: mean=-0.005074, std=0.097642\n",
      "  grad: mean=0.000012, std=0.000668\n",
      "base_model.features.9.conv.2.weight: mean=-0.000783, std=0.053251\n",
      "  grad: mean=0.000001, std=0.000372\n",
      "base_model.features.9.conv.3.weight: mean=0.249984, std=0.051023\n",
      "  grad: mean=0.000060, std=0.001867\n",
      "base_model.features.9.conv.3.bias: mean=-0.000000, std=0.000003\n",
      "  grad: mean=0.000000, std=0.000000\n",
      "base_model.features.10.conv.0.0.weight: mean=0.000650, std=0.057655\n",
      "  grad: mean=-0.000001, std=0.000463\n",
      "base_model.features.10.conv.0.1.weight: mean=0.108536, std=0.026211\n",
      "  grad: mean=-0.000047, std=0.001231\n",
      "base_model.features.10.conv.0.1.bias: mean=0.024647, std=0.075545\n",
      "  grad: mean=-0.000051, std=0.000850\n",
      "base_model.features.10.conv.1.0.weight: mean=0.003828, std=0.080831\n",
      "  grad: mean=-0.000012, std=0.000437\n",
      "base_model.features.10.conv.1.1.weight: mean=0.166240, std=0.045262\n",
      "  grad: mean=-0.000021, std=0.001011\n",
      "base_model.features.10.conv.1.1.bias: mean=-0.000011, std=0.114165\n",
      "  grad: mean=-0.000041, std=0.000514\n",
      "base_model.features.10.conv.2.weight: mean=0.001971, std=0.054368\n",
      "  grad: mean=0.000000, std=0.000264\n",
      "base_model.features.10.conv.3.weight: mean=0.267407, std=0.050134\n",
      "  grad: mean=-0.000178, std=0.001363\n",
      "base_model.features.10.conv.3.bias: mean=0.000000, std=0.000002\n",
      "  grad: mean=-0.000000, std=0.000000\n",
      "base_model.features.11.conv.0.0.weight: mean=-0.002481, std=0.081685\n",
      "  grad: mean=-0.000003, std=0.000333\n",
      "base_model.features.11.conv.0.1.weight: mean=0.134141, std=0.027702\n",
      "  grad: mean=0.000007, std=0.000568\n",
      "base_model.features.11.conv.0.1.bias: mean=0.064097, std=0.085441\n",
      "  grad: mean=-0.000022, std=0.000546\n",
      "base_model.features.11.conv.1.0.weight: mean=0.007727, std=0.111340\n",
      "  grad: mean=-0.000009, std=0.000500\n",
      "base_model.features.11.conv.1.1.weight: mean=0.213800, std=0.055051\n",
      "  grad: mean=0.000025, std=0.000919\n",
      "base_model.features.11.conv.1.1.bias: mean=0.090712, std=0.143363\n",
      "  grad: mean=-0.000027, std=0.000535\n",
      "base_model.features.11.conv.2.weight: mean=0.000555, std=0.071361\n",
      "  grad: mean=-0.000002, std=0.000294\n",
      "base_model.features.11.conv.3.weight: mean=0.374664, std=0.044932\n",
      "  grad: mean=-0.000084, std=0.001267\n",
      "base_model.features.11.conv.3.bias: mean=-0.000000, std=0.000004\n",
      "  grad: mean=0.000000, std=0.000000\n",
      "base_model.features.12.conv.0.0.weight: mean=-0.000095, std=0.053830\n",
      "  grad: mean=0.000001, std=0.000271\n",
      "base_model.features.12.conv.0.1.weight: mean=0.119935, std=0.029313\n",
      "  grad: mean=0.000053, std=0.001292\n",
      "base_model.features.12.conv.0.1.bias: mean=0.009771, std=0.086386\n",
      "  grad: mean=0.000024, std=0.000585\n",
      "base_model.features.12.conv.1.0.weight: mean=0.001308, std=0.081157\n",
      "  grad: mean=-0.000009, std=0.000340\n",
      "base_model.features.12.conv.1.1.weight: mean=0.184218, std=0.047175\n",
      "  grad: mean=-0.000000, std=0.000688\n",
      "base_model.features.12.conv.1.1.bias: mean=-0.013402, std=0.116314\n",
      "  grad: mean=-0.000011, std=0.000419\n",
      "base_model.features.12.conv.2.weight: mean=-0.000011, std=0.052381\n",
      "  grad: mean=-0.000006, std=0.000210\n",
      "base_model.features.12.conv.3.weight: mean=0.249181, std=0.042325\n",
      "  grad: mean=0.000155, std=0.000923\n",
      "base_model.features.12.conv.3.bias: mean=-0.000000, std=0.000003\n",
      "  grad: mean=0.000000, std=0.000000\n",
      "base_model.features.13.conv.0.0.weight: mean=0.000312, std=0.055001\n",
      "  grad: mean=-0.000000, std=0.000217\n",
      "base_model.features.13.conv.0.1.weight: mean=0.121443, std=0.030529\n",
      "  grad: mean=0.000017, std=0.000371\n",
      "base_model.features.13.conv.0.1.bias: mean=-0.001557, std=0.076797\n",
      "  grad: mean=-0.000012, std=0.000432\n",
      "base_model.features.13.conv.1.0.weight: mean=0.004069, std=0.075203\n",
      "  grad: mean=0.000012, std=0.000285\n",
      "base_model.features.13.conv.1.1.weight: mean=0.177920, std=0.049727\n",
      "  grad: mean=0.000012, std=0.000660\n",
      "base_model.features.13.conv.1.1.bias: mean=-0.006661, std=0.132711\n",
      "  grad: mean=0.000002, std=0.000377\n",
      "base_model.features.13.conv.2.weight: mean=0.000200, std=0.051686\n",
      "  grad: mean=-0.000005, std=0.000187\n",
      "base_model.features.13.conv.3.weight: mean=0.299676, std=0.070361\n",
      "  grad: mean=0.000020, std=0.000782\n",
      "base_model.features.13.conv.3.bias: mean=-0.000000, std=0.000002\n",
      "  grad: mean=0.000000, std=0.000000\n",
      "base_model.features.14.conv.0.0.weight: mean=-0.001567, std=0.070628\n",
      "  grad: mean=0.000001, std=0.000225\n",
      "base_model.features.14.conv.0.1.weight: mean=0.175802, std=0.040866\n",
      "  grad: mean=-0.000017, std=0.000451\n",
      "base_model.features.14.conv.0.1.bias: mean=-0.070974, std=0.110363\n",
      "  grad: mean=0.000008, std=0.000605\n",
      "base_model.features.14.conv.1.0.weight: mean=0.020200, std=0.074544\n",
      "  grad: mean=-0.000001, std=0.000262\n",
      "base_model.features.14.conv.1.1.weight: mean=0.188549, std=0.053207\n",
      "  grad: mean=0.000021, std=0.000907\n",
      "base_model.features.14.conv.1.1.bias: mean=0.135353, std=0.118220\n",
      "  grad: mean=-0.000011, std=0.000362\n",
      "base_model.features.14.conv.2.weight: mean=-0.000126, std=0.063187\n",
      "  grad: mean=-0.000002, std=0.000226\n",
      "base_model.features.14.conv.3.weight: mean=0.233400, std=0.051337\n",
      "  grad: mean=0.000009, std=0.001565\n",
      "base_model.features.14.conv.3.bias: mean=-0.000000, std=0.000005\n",
      "  grad: mean=0.000000, std=0.000000\n",
      "base_model.features.15.conv.0.0.weight: mean=0.000026, std=0.044629\n",
      "  grad: mean=0.000001, std=0.000162\n",
      "base_model.features.15.conv.0.1.weight: mean=0.125375, std=0.029829\n",
      "  grad: mean=0.000007, std=0.000284\n",
      "base_model.features.15.conv.0.1.bias: mean=0.039526, std=0.062125\n",
      "  grad: mean=-0.000001, std=0.000435\n",
      "base_model.features.15.conv.1.0.weight: mean=-0.005549, std=0.080219\n",
      "  grad: mean=-0.000006, std=0.000252\n",
      "base_model.features.15.conv.1.1.weight: mean=0.188524, std=0.051295\n",
      "  grad: mean=0.000004, std=0.000542\n",
      "base_model.features.15.conv.1.1.bias: mean=-0.008592, std=0.091900\n",
      "  grad: mean=0.000007, std=0.000405\n",
      "base_model.features.15.conv.2.weight: mean=0.000065, std=0.045121\n",
      "  grad: mean=0.000001, std=0.000154\n",
      "base_model.features.15.conv.3.weight: mean=0.212690, std=0.047906\n",
      "  grad: mean=-0.000074, std=0.000945\n",
      "base_model.features.15.conv.3.bias: mean=-0.000000, std=0.000004\n",
      "  grad: mean=0.000000, std=0.000000\n",
      "base_model.features.16.conv.0.0.weight: mean=0.000175, std=0.049436\n",
      "  grad: mean=0.000000, std=0.000161\n",
      "base_model.features.16.conv.0.1.weight: mean=0.130819, std=0.035061\n",
      "  grad: mean=-0.000002, std=0.000292\n",
      "base_model.features.16.conv.0.1.bias: mean=0.020177, std=0.069749\n",
      "  grad: mean=0.000010, std=0.000492\n",
      "base_model.features.16.conv.1.0.weight: mean=0.003274, std=0.071097\n",
      "  grad: mean=-0.000004, std=0.000234\n",
      "base_model.features.16.conv.1.1.weight: mean=0.193150, std=0.057424\n",
      "  grad: mean=-0.000001, std=0.000500\n",
      "base_model.features.16.conv.1.1.bias: mean=0.007556, std=0.094095\n",
      "  grad: mean=-0.000010, std=0.000375\n",
      "base_model.features.16.conv.2.weight: mean=-0.000231, std=0.046557\n",
      "  grad: mean=0.000003, std=0.000152\n",
      "base_model.features.16.conv.3.weight: mean=0.408151, std=0.165528\n",
      "  grad: mean=0.000028, std=0.000557\n",
      "base_model.features.16.conv.3.bias: mean=0.000000, std=0.000002\n",
      "  grad: mean=-0.000000, std=0.000000\n",
      "base_model.features.17.conv.0.0.weight: mean=0.001314, std=0.056794\n",
      "  grad: mean=-0.000000, std=0.000194\n",
      "base_model.features.17.conv.0.1.weight: mean=0.241886, std=0.082109\n",
      "  grad: mean=-0.000007, std=0.000915\n",
      "base_model.features.17.conv.0.1.bias: mean=-0.060208, std=0.066166\n",
      "  grad: mean=-0.000011, std=0.002040\n",
      "base_model.features.17.conv.1.0.weight: mean=0.000321, std=0.025578\n",
      "  grad: mean=-0.000020, std=0.000532\n",
      "base_model.features.17.conv.1.1.weight: mean=0.185466, std=0.047468\n",
      "  grad: mean=-0.000010, std=0.000662\n",
      "base_model.features.17.conv.1.1.bias: mean=0.096689, std=0.082845\n",
      "  grad: mean=0.000016, std=0.000331\n",
      "base_model.features.17.conv.2.weight: mean=0.000005, std=0.041946\n",
      "  grad: mean=-0.000000, std=0.000148\n",
      "base_model.features.17.conv.3.weight: mean=0.234574, std=0.004682\n",
      "  grad: mean=0.000000, std=0.000615\n",
      "base_model.features.17.conv.3.bias: mean=0.000000, std=0.000001\n",
      "  grad: mean=-0.000000, std=0.000000\n",
      "base_model.features.18.0.weight: mean=-0.000240, std=0.030603\n",
      "  grad: mean=0.000000, std=0.000137\n",
      "base_model.features.18.1.weight: mean=1.504350, std=0.033009\n",
      "  grad: mean=0.000000, std=0.000077\n",
      "base_model.features.18.1.bias: mean=-0.148933, std=0.054553\n",
      "  grad: mean=-0.000000, std=0.000073\n",
      "feature_refiner.0.weight: mean=0.000039, std=0.016143\n",
      "  grad: mean=-0.000009, std=0.000287\n",
      "feature_refiner.0.bias: mean=0.000165, std=0.015949\n",
      "  grad: mean=-0.000017, std=0.000375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 [Train]: 100%|██████████| 94/94 [00:20<00:00,  4.54it/s, loss=0.0505, acc=0.974]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Set Analysis:\n",
      "Total samples: 80\n",
      "Fire samples: 17 (21.2%)\n",
      "No-fire samples: 63 (78.8%)\n",
      "Fire accuracy: 100.0% (17/17)\n",
      "No-fire accuracy: 100.0% (63/63)\n",
      "Prediction distribution: 21.2% fire predictions\n",
      "\n",
      "First 10 validation predictions:\n",
      "✅ Sample 1: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 2: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 3: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 4: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 5: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 6: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 7: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 8: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 9: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 10: Predicted No-fire, Actual No-fire\n",
      "New best model with val_acc: 1.0000\n",
      "\n",
      "Epoch 1/15 Summary:\n",
      " - Train Loss: 0.1375, Train Acc: 0.9739\n",
      " - Val Loss: 0.0006, Val Acc: 1.0000\n",
      " - LR: 1.00e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 [Train]: 100%|██████████| 94/94 [00:22<00:00,  4.27it/s, loss=0.0522, acc=0.998]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Set Analysis:\n",
      "Total samples: 80\n",
      "Fire samples: 17 (21.2%)\n",
      "No-fire samples: 63 (78.8%)\n",
      "Fire accuracy: 100.0% (17/17)\n",
      "No-fire accuracy: 100.0% (63/63)\n",
      "Prediction distribution: 21.2% fire predictions\n",
      "\n",
      "First 10 validation predictions:\n",
      "✅ Sample 1: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 2: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 3: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 4: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 5: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 6: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 7: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 8: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 9: Predicted No-fire, Actual No-fire\n",
      "✅ Sample 10: Predicted No-fire, Actual No-fire\n",
      "\n",
      "Epoch 2/15 Summary:\n",
      " - Train Loss: 0.0132, Train Acc: 0.9980\n",
      " - Val Loss: 0.0001, Val Acc: 1.0000\n",
      " - LR: 1.00e-04\n",
      "Warning: Perfect validation accuracy detected. Stopping early for investigation.\n",
      "Saved training history plot to 'Figures/CNN_training_history.png'\n",
      "Saved best model weights to 'Saved_Features/CNN_best_model_weights.pth'\n",
      "\n",
      "Evaluating model on test set...\n",
      "Test Accuracy: 1.0000\n",
      "Test Accuracy: 1.0000\n",
      "\n",
      "Saving feature extractor weights...\n",
      "CNN feature extractor saved to Saved_Features/CNN_fire_feature_extractor.pth (without classifier)\n",
      "\n",
      "Feature Extraction Summary:\n",
      "Extracted 80 feature vectors\n",
      "Feature vector shape: (512,)\n",
      "Sample feature (first 10 values): [0.        2.0929544 0.        0.        0.        2.0226784 0.\n",
      " 1.6750109 0.        0.       ]\n",
      "...\n",
      "\n",
      "Saving features for ensemble model training...\n",
      "Features and labels saved in Saved_Features/ directory\n",
      "\n",
      "Total Execution Time: 51.37 seconds (0.86 minutes)\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T22:56:01.092Z",
     "start_time": "2025-07-31T22:56:01.088951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- TEST SET FEATURE ANALYSIS ---\n",
    "# Print dataset statistics after feature extraction\n",
    "print(f\"Number of test samples: {len(test_labels)}\")       # Total test instances processed\n",
    "print(f\"Feature matrix shape: {test_features.shape}\")      # Dimensions: [samples x features]\n",
    "print(f\"Feature dimension: {test_features.shape[1]}\")      # Size of each feature vector"
   ],
   "id": "fe7b8d850d742c61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 80\n",
      "Feature matrix shape: (80, 512)\n",
      "Feature dimension: 512\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T23:24:50.090027Z",
     "start_time": "2025-07-31T23:24:50.057456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_new_image(model, image_path, transform, device):\n",
    "    img = Image.open(image_path)\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        prob = torch.sigmoid(output).item()\n",
    "        return \"Fire\" if prob < 0.5 else \"No-fire\", prob\n",
    "\n",
    "# Usage:\n",
    "test_transform = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.Grayscale(num_output_channels=1),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "prediction, confidence = predict_new_image(\n",
    "    trained_model,\n",
    "    \"dataset/raw/thermal/fire/00008.JPG\",\n",
    "    test_transform,\n",
    "    device\n",
    ")\n",
    "print(f\"Prediction: {prediction} with confidence: {confidence:.2f}\")"
   ],
   "id": "d3194fa7828c173d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Fire with confidence: 0.00\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## NN classifer",
   "id": "2bc2106aceca6daf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset",
   "id": "d2cb938835e2ea53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:34:23.403730Z",
     "start_time": "2025-08-02T14:34:23.400027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset for multi-modal inputs (ViT + CNN)\n",
    "class DualInputDataset(Dataset):\n",
    "    def __init__(self, vit_image_paths, cnn_image_paths, labels, vit_transform, cnn_transform):\n",
    "        \"\"\"\n",
    "        Dataset for dual-input models (RGB + thermal)\n",
    "\n",
    "        Args:\n",
    "            vit_image_paths: List of paths to RGB images (ViT input)\n",
    "            cnn_image_paths: List of paths to thermal images (CNN input)\n",
    "            labels: List of corresponding labels\n",
    "            vit_transform: Transform pipeline for ViT images\n",
    "            cnn_transform: Transform pipeline for CNN images\n",
    "        \"\"\"\n",
    "        self.vit_image_paths = vit_image_paths\n",
    "        self.cnn_image_paths = cnn_image_paths\n",
    "        self.labels = labels\n",
    "        self.vit_transform = vit_transform\n",
    "        self.cnn_transform = cnn_transform\n",
    "\n",
    "        # Validate data alignment\n",
    "        if len(vit_image_paths) != len(cnn_image_paths) or len(vit_image_paths) != len(labels):\n",
    "            raise ValueError(\"Input lengths mismatch: ViT paths, CNN paths and labels must be equal\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns total number of samples\"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Loads and transforms image pair, returns (vit_input, cnn_input, label)\"\"\"\n",
    "        # Process RGB image for ViT\n",
    "        vit_img = Image.open(self.vit_image_paths[idx]).convert('RGB')\n",
    "        vit_tensor = self.vit_transform(vit_img)\n",
    "\n",
    "        # Process thermal image for CNN\n",
    "        cnn_img = Image.open(self.cnn_image_paths[idx])\n",
    "        cnn_tensor = self.cnn_transform(cnn_img)\n",
    "\n",
    "        # Convert label to tensor\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "\n",
    "        return vit_tensor, cnn_tensor, label"
   ],
   "id": "b0c77c01e7e6244e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:34:26.560306Z",
     "start_time": "2025-08-02T14:34:26.555209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def denormalize_tensor(tensor, mean, std):\n",
    "    \"\"\"Denormalize tensor using mean and std\"\"\"\n",
    "    if tensor.dim() == 4:  # batch dimension\n",
    "        for t, m, s in zip(tensor, mean, std):\n",
    "            t.mul_(s).add_(m)\n",
    "        return tensor\n",
    "    else:\n",
    "        return tensor * torch.tensor(std).view(-1, 1, 1) + torch.tensor(mean).view(-1, 1, 1)\n",
    "\n",
    "def generate_augmented_images(image_paths, transform, output_dir, modality, num_copies):\n",
    "    \"\"\"\n",
    "    Generate and save augmented images to disk\n",
    "    Returns list of paths to augmented images\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    new_paths = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        img = Image.open(path)\n",
    "        base_name = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "        for j in range(num_copies):\n",
    "            # Apply transformation\n",
    "            tensor = transform(img)\n",
    "\n",
    "            # Denormalize for saving\n",
    "            if modality == 'RGB':\n",
    "                denorm_tensor = denormalize_tensor(\n",
    "                    tensor,\n",
    "                    [0.485, 0.456, 0.406],\n",
    "                    [0.229, 0.224, 0.225]\n",
    "                )\n",
    "            elif modality == 'thermal':\n",
    "                denorm_tensor = denormalize_tensor(\n",
    "                    tensor,\n",
    "                    [0.5],\n",
    "                    [0.5]\n",
    "                )\n",
    "                denorm_tensor = denorm_tensor.squeeze(0)  # Remove channel dim\n",
    "                pil_img = transforms.ToPILImage()(denorm_tensor.cpu())\n",
    "\n",
    "            # Convert to PIL and save\n",
    "            if modality == 'RGB':\n",
    "                pil_img = transforms.ToPILImage()(denorm_tensor)\n",
    "            else:\n",
    "                # Handle grayscale separately\n",
    "                pil_img = transforms.ToPILImage()(denorm_tensor.squeeze(0))\n",
    "\n",
    "            new_filename = f\"{base_name}_aug{j}.jpg\"\n",
    "            new_path = os.path.join(output_dir, new_filename)\n",
    "            pil_img.save(new_path)\n",
    "            new_paths.append(new_path)\n",
    "\n",
    "    return new_paths"
   ],
   "id": "252aa7c9e7ed62ff",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:34:34.441871Z",
     "start_time": "2025-08-02T14:34:34.424194Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare multimodal datasets for fusion model training\n",
    "def prepare_fusion_data(vit_fire_dir, vit_non_fire_dir, cnn_fire_dir, cnn_non_fire_dir):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"Preparing multimodal fusion dataset\")\n",
    "    print(f\"ViT fire (RGB) directory: {vit_fire_dir}\")\n",
    "    print(f\"ViT non-fire (RGB) directory: {vit_non_fire_dir}\")\n",
    "    print(f\"CNN fire (thermal) directory: {cnn_fire_dir}\")\n",
    "    print(f\"CNN non-fire (thermal) directory: {cnn_non_fire_dir}\")\n",
    "\n",
    "    # Normalizes filenames for matching across modalities\n",
    "    def get_base_name(filename):\n",
    "        base = os.path.splitext(filename)[0]  # Remove extension\n",
    "        base = re.sub(r'^(RGB_|THERMAL_|IMG_|DSC_)', '', base)  # Remove prefixes\n",
    "        return re.sub(r'[^a-zA-Z0-9]', '', base).lower()  # Standardize format\n",
    "\n",
    "    # Process RGB images for ViT model\n",
    "    vit_mapping = {}\n",
    "    # Process fire RGB images\n",
    "    if os.path.isdir(vit_fire_dir):\n",
    "        print(f\"Processing ViT fire images\")\n",
    "        for filename in os.listdir(vit_fire_dir):\n",
    "            if not filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                continue\n",
    "            base_name = get_base_name(filename)\n",
    "            vit_mapping[base_name] = {\"path\": os.path.join(vit_fire_dir, filename), \"label\": 1}\n",
    "\n",
    "    # Process non-fire RGB images\n",
    "    if os.path.isdir(vit_non_fire_dir):\n",
    "        print(f\"Processing ViT non-fire images\")\n",
    "        for filename in os.listdir(vit_non_fire_dir):\n",
    "            if not filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                continue\n",
    "            base_name = get_base_name(filename)\n",
    "            vit_mapping[base_name] = {\"path\": os.path.join(vit_non_fire_dir, filename), \"label\": 0}\n",
    "\n",
    "    print(f\"ViT images found: {len(vit_mapping)}\")\n",
    "\n",
    "    # Process thermal images for CNN model\n",
    "    cnn_mapping = {}\n",
    "    # Process fire thermal images\n",
    "    if os.path.isdir(cnn_fire_dir):\n",
    "        print(f\"Processing CNN fire images\")\n",
    "        for filename in os.listdir(cnn_fire_dir):\n",
    "            if not filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                continue\n",
    "            base_name = get_base_name(filename)\n",
    "            cnn_mapping[base_name] = {\"path\": os.path.join(cnn_fire_dir, filename), \"label\": 1}\n",
    "\n",
    "    # Process non-fire thermal images\n",
    "    if os.path.isdir(cnn_non_fire_dir):\n",
    "        print(f\"Processing CNN non-fire images\")\n",
    "        for filename in os.listdir(cnn_non_fire_dir):\n",
    "            if not filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                continue\n",
    "            base_name = get_base_name(filename)\n",
    "            cnn_mapping[base_name] = {\"path\": os.path.join(cnn_non_fire_dir, filename), \"label\": 0}\n",
    "\n",
    "    print(f\"CNN images found: {len(cnn_mapping)}\")\n",
    "\n",
    "    # Match image pairs across modalities\n",
    "    matched_pairs = []\n",
    "    for key in set(vit_mapping.keys()) & set(cnn_mapping.keys()):  # Intersection of keys\n",
    "        vit_data = vit_mapping[key]\n",
    "        cnn_data = cnn_mapping[key]\n",
    "\n",
    "        # Verify consistent labeling\n",
    "        if vit_data[\"label\"] != cnn_data[\"label\"]:\n",
    "            print(f\"Label mismatch for {key}: ViT={vit_data['label']}, CNN={cnn_data['label']}\")\n",
    "            continue\n",
    "\n",
    "        matched_pairs.append((vit_data[\"path\"], cnn_data[\"path\"], vit_data[\"label\"]))\n",
    "\n",
    "    print(f\"Total matched pairs: {len(matched_pairs)}\")\n",
    "\n",
    "    # Analyze class distribution\n",
    "    fire_pairs = [p for p in matched_pairs if p[2] == 1]\n",
    "    non_fire_pairs = [p for p in matched_pairs if p[2] == 0]\n",
    "    print(f\"Fire pairs: {len(fire_pairs)}, Non-fire pairs: {len(non_fire_pairs)}\")\n",
    "\n",
    "    # Handle insufficient data scenarios\n",
    "    if not matched_pairs:\n",
    "        # Diagnostic output for debugging\n",
    "        print(\"\\nSample ViT keys:\", list(vit_mapping.keys())[:5])\n",
    "        print(\"Sample CNN keys:\", list(cnn_mapping.keys())[:5])\n",
    "        raise ValueError(\"No matching pairs found. Check filename patterns and directories.\")\n",
    "\n",
    "    # Balance classes if both present\n",
    "    if fire_pairs and non_fire_pairs:\n",
    "        n_per_class = min(len(fire_pairs), len(non_fire_pairs))\n",
    "        all_pairs = fire_pairs[:n_per_class] + non_fire_pairs[:n_per_class]\n",
    "        print(f\"Balanced dataset: {n_per_class} per class\")\n",
    "    else:\n",
    "        all_pairs = matched_pairs\n",
    "        print(\"Using all available pairs (single class)\")\n",
    "\n",
    "    # Shuffle dataset\n",
    "    np.random.shuffle(all_pairs)\n",
    "    vit_paths, cnn_paths, labels = zip(*all_pairs)  # Unzip pairs\n",
    "\n",
    "    # Stratified split into train/val/test (70/15/15)\n",
    "    train_idx, test_idx = train_test_split(\n",
    "        range(len(labels)),\n",
    "        test_size=0.7,\n",
    "        random_state=42,\n",
    "        stratify=labels\n",
    "    )\n",
    "    test_idx, val_idx = train_test_split(\n",
    "        test_idx,\n",
    "        test_size=0.5,\n",
    "        random_state=42,\n",
    "        stratify=[labels[i] for i in test_idx]\n",
    "    )\n",
    "\n",
    "    # Create split indices\n",
    "    vit_train = [vit_paths[i] for i in train_idx]\n",
    "    cnn_train = [cnn_paths[i] for i in train_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "\n",
    "    vit_val = [vit_paths[i] for i in val_idx]\n",
    "    cnn_val = [cnn_paths[i] for i in val_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    vit_test = [vit_paths[i] for i in test_idx]\n",
    "    cnn_test = [cnn_paths[i] for i in test_idx]\n",
    "    test_labels = [labels[i] for i in test_idx]\n",
    "\n",
    "    # Dataset statistics\n",
    "    print(f\"\\nDataset splits:\")\n",
    "    print(f\"Train: {len(vit_train)} pairs\")\n",
    "    print(f\"Validation: {len(vit_val)} pairs\")\n",
    "    print(f\"Test: {len(vit_test)} pairs\")\n",
    "\n",
    "    # Transformation pipelines\n",
    "    # ViT (RGB) transforms\n",
    "    vit_train_transform = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    vit_eval_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # CNN (thermal) transforms\n",
    "    cnn_train_transform = v2.Compose([\n",
    "        v2.RandomResizedCrop(size=(224, 224)),\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ])\n",
    "\n",
    "    cnn_eval_transform = v2.Compose([\n",
    "        v2.Resize(size=(224, 224)),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ])\n",
    "\n",
    "    print(\"\\nGenerating augmented training images...\")\n",
    "    num_aug_copies = 10  # Generate num augmented copies per original image\n",
    "\n",
    "    # Create output directories\n",
    "    processed_rgb_dir = \"dataset/processed/RGB\"\n",
    "    processed_thermal_dir = \"dataset/processed/thermal\"\n",
    "\n",
    "    # Generate augmented RGB images\n",
    "    aug_rgb_paths = generate_augmented_images(\n",
    "        vit_train,\n",
    "        vit_train_transform,\n",
    "        processed_rgb_dir,\n",
    "        'RGB',\n",
    "        num_aug_copies\n",
    "    )\n",
    "\n",
    "    # Generate augmented thermal images\n",
    "    aug_thermal_paths = generate_augmented_images(\n",
    "        cnn_train,\n",
    "        cnn_train_transform,\n",
    "        processed_thermal_dir,\n",
    "        'thermal',\n",
    "        num_aug_copies\n",
    "    )\n",
    "\n",
    "    # Combine original and augmented paths\n",
    "    vit_train_combined = vit_train + aug_rgb_paths\n",
    "    cnn_train_combined = cnn_train + aug_thermal_paths\n",
    "    train_labels_combined = train_labels + train_labels * num_aug_copies\n",
    "\n",
    "    # Verify new sizes\n",
    "    print(f\"\\nAugmented dataset sizes:\")\n",
    "    print(f\"Original RGB training images: {len(vit_train)}\")\n",
    "    print(f\"Original thermal training images: {len(cnn_train)}\")\n",
    "    print(f\"Augmented RGB images: {len(aug_rgb_paths)}\")\n",
    "    print(f\"Augmented thermal images: {len(aug_thermal_paths)}\")\n",
    "    print(f\"RGB Combined training set: {len(vit_train_combined)}\")\n",
    "    print(f\"Thermal Combined training set: {len(cnn_train_combined)}\")\n",
    "    print(f\"Combined training set: {len(train_labels_combined)} pairs\")\n",
    "\n",
    "    # Create new transforms for training (only normalization since augmentation is pre-generated)\n",
    "    vit_train_transform_final = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Ensure correct size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    cnn_train_transform_final = v2.Compose([\n",
    "        v2.Resize((224, 224)),\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ])\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = DualInputDataset(\n",
    "        vit_train_combined,\n",
    "        cnn_train_combined,\n",
    "        train_labels_combined,\n",
    "        vit_train_transform_final,\n",
    "        cnn_train_transform_final\n",
    "    )\n",
    "\n",
    "    val_dataset = DualInputDataset(\n",
    "        vit_val,\n",
    "        cnn_val,\n",
    "        val_labels,\n",
    "        vit_eval_transform,\n",
    "        cnn_eval_transform\n",
    "    )\n",
    "\n",
    "    test_dataset = DualInputDataset(\n",
    "        vit_test,\n",
    "        cnn_test,\n",
    "        test_labels,\n",
    "        vit_eval_transform,\n",
    "        cnn_eval_transform\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    batch_size = 16\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTrain dataset sizes: {len(train_dataset)} = {len(train_dataloader)} batches\")\n",
    "    print(f\"Val dataset sizes: {len(val_dataset)} = {len(val_dataloader)} batches\")\n",
    "    print(f\"Test dataset sizes: {len(test_dataset)} = {len(test_dataloader)} batches\")\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ],
   "id": "4e4bfdc91b7b5af6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Create Dataset",
   "id": "6ad98e87f58e951d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:35:34.285192Z",
     "start_time": "2025-08-02T14:34:54.293831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset paths\n",
    "vit_fire_dir = \"dataset/raw/RGB/fire\"\n",
    "vit_non_fire_dir = \"dataset/raw/RGB/no_fire\"\n",
    "cnn_fire_dir = \"dataset/raw/thermal/fire\"\n",
    "cnn_non_fire_dir = \"dataset/raw/thermal/no_fire\"\n",
    "\n",
    "# Prepare Dataset\n",
    "print(\"\\nPreparing fusion datasets...\")\n",
    "train_loader, val_loader, test_loader = prepare_fusion_data(\n",
    "    vit_fire_dir, vit_non_fire_dir, cnn_fire_dir, cnn_non_fire_dir\n",
    ")"
   ],
   "id": "c7d6423733edd076",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing fusion datasets...\n",
      "\n",
      "==================================================\n",
      "Preparing multimodal fusion dataset\n",
      "ViT fire (RGB) directory: dataset/raw/RGB/fire\n",
      "ViT non-fire (RGB) directory: dataset/raw/RGB/no_fire\n",
      "CNN fire (thermal) directory: dataset/raw/thermal/fire\n",
      "CNN non-fire (thermal) directory: dataset/raw/thermal/no_fire\n",
      "Processing ViT fire images\n",
      "Processing ViT non-fire images\n",
      "ViT images found: 529\n",
      "Processing CNN fire images\n",
      "Processing CNN non-fire images\n",
      "CNN images found: 417\n",
      "Total matched pairs: 417\n",
      "Fire pairs: 301, Non-fire pairs: 116\n",
      "Balanced dataset: 116 per class\n",
      "\n",
      "Dataset splits:\n",
      "Train: 69 pairs\n",
      "Validation: 82 pairs\n",
      "Test: 81 pairs\n",
      "\n",
      "Generating augmented training images...\n",
      "\n",
      "Augmented dataset sizes:\n",
      "Original RGB training images: 69\n",
      "Original thermal training images: 69\n",
      "Augmented RGB images: 690\n",
      "Augmented thermal images: 690\n",
      "RGB Combined training set: 759\n",
      "Thermal Combined training set: 759\n",
      "Combined training set: 759 pairs\n",
      "\n",
      "Train dataset sizes: 759 = 48 batches\n",
      "Val dataset sizes: 82 = 6 batches\n",
      "Test dataset sizes: 81 = 6 batches\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### NN Model",
   "id": "d57682336d9ebf71"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:35:53.047155Z",
     "start_time": "2025-08-02T14:35:53.025846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fusion Model combining ViT and CNN features\n",
    "class FusionModel(pl.LightningModule):\n",
    "    def __init__(self, vit_extractor, cnn_extractor, config=None, visuals=True):\n",
    "        \"\"\"\n",
    "        Multimodal fusion model combining ViT (RGB) and CNN (thermal) features.\n",
    "\n",
    "        Args:\n",
    "            vit_extractor: Pretrained ViT feature extractor\n",
    "            cnn_extractor: Pretrained CNN feature extractor\n",
    "            config: Configuration dictionary for hyperparameters\n",
    "            visuals: Enable advanced visualization metrics\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Configuration setup\n",
    "        default_config = {\n",
    "            \"lr\": 1e-3,                # Learning rate\n",
    "            \"weight_decay\": 1e-4,      # L2 regularization\n",
    "            \"dropout_rate\": 0.4,       # Dropout probability\n",
    "            \"hidden_dim\": 512,         # Fusion layer dimension\n",
    "            \"pos_weight\": 1.0          # Class imbalance weight\n",
    "        }\n",
    "        if config:\n",
    "            default_config.update(config)  # Merge with user config\n",
    "        self.config = default_config\n",
    "\n",
    "        # Visualization settings\n",
    "        self.visuals = visuals\n",
    "        self.save_hyperparameters(ignore=[\"vit_extractor\", \"cnn_extractor\"])\n",
    "\n",
    "        # Feature extractors (frozen)\n",
    "        self.vit_extractor = vit_extractor\n",
    "        self.cnn_extractor = cnn_extractor\n",
    "\n",
    "        # Freeze extractors to preserve learned features\n",
    "        for param in self.vit_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.cnn_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Fusion classifier network\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768 + 512, self.config[\"hidden_dim\"]),  # Combine features\n",
    "            nn.ReLU(),                                        # Non-linearity\n",
    "            nn.BatchNorm1d(self.config[\"hidden_dim\"]),        # Stabilization\n",
    "            nn.Dropout(self.config[\"dropout_rate\"]),          # Regularization\n",
    "            nn.Linear(self.config[\"hidden_dim\"], 1)           # Binary output\n",
    "        )\n",
    "\n",
    "        # Loss function with class weighting\n",
    "        self.criterion = nn.BCEWithLogitsLoss(\n",
    "            pos_weight=torch.tensor(self.config[\"pos_weight\"])\n",
    "        )\n",
    "\n",
    "        # Core metrics\n",
    "        self.train_acc = Accuracy(task='binary')\n",
    "        self.val_acc = Accuracy(task='binary')\n",
    "        self.test_acc = Accuracy(task='binary')\n",
    "\n",
    "        self.train_acc_history = []  # Store training accuracy per epoch\n",
    "        self.val_acc_history = []    # Store validation accuracy per epoch\n",
    "\n",
    "        # Advanced metrics for visualization\n",
    "        if self.visuals:\n",
    "            # F1 Scores\n",
    "            self.train_f1 = F1Score(task='binary')\n",
    "            self.val_f1 = F1Score(task='binary')\n",
    "            self.test_f1 = F1Score(task='binary')\n",
    "\n",
    "            # Precision metrics\n",
    "            self.train_precision = Precision(task='binary')\n",
    "            self.val_precision = Precision(task='binary')\n",
    "            self.test_precision = Precision(task='binary')\n",
    "\n",
    "            # Recall metrics\n",
    "            self.train_recall = Recall(task='binary')\n",
    "            self.val_recall = Recall(task='binary')\n",
    "            self.test_recall = Recall(task='binary')\n",
    "\n",
    "        # Storage for test visualizations\n",
    "        self.test_preds = []    # Predicted labels\n",
    "        self.test_targets = []  # Ground truth labels\n",
    "        self.test_probs = []    # Prediction probabilities\n",
    "\n",
    "    def forward(self, vit_input, cnn_input):\n",
    "        \"\"\"Forward pass through both feature extractors and fusion classifier\"\"\"\n",
    "        # Extract features from both modalities\n",
    "        vit_features = self.vit_extractor(vit_input)  # RGB features (768-dim)\n",
    "        _, cnn_features = self.cnn_extractor(cnn_input, return_features=True)  # Thermal features (512-dim)\n",
    "\n",
    "        # Concatenate features along channel dimension\n",
    "        combined = torch.cat((vit_features, cnn_features), dim=1)\n",
    "        return self.classifier(combined).squeeze(1)  # Remove extra dimension\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"Single training step with metrics calculation\"\"\"\n",
    "        vit_imgs, cnn_imgs, labels = batch\n",
    "        logits = self(vit_imgs, cnn_imgs)  # Forward pass\n",
    "        loss = self.criterion(logits, labels)  # Compute loss\n",
    "\n",
    "        # Convert to probabilities and predictions\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = probs > 0.5  # Threshold at 0.5\n",
    "\n",
    "        # Update metrics\n",
    "        self.train_acc(preds, labels)\n",
    "        if self.visuals:\n",
    "            self.train_f1(preds, labels)\n",
    "            self.train_precision(preds, labels)\n",
    "            self.train_recall(preds, labels)\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc\", self.train_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        if self.visuals:\n",
    "            self.log(\"train_f1\", self.train_f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "            self.log(\"train_precision\", self.train_precision, on_step=False, on_epoch=True)\n",
    "            self.log(\"train_recall\", self.train_recall, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        \"\"\"Reset training metrics at the beginning of each epoch\"\"\"\n",
    "        self.train_acc.reset()\n",
    "        if self.visuals:\n",
    "            self.train_f1.reset()\n",
    "            self.train_precision.reset()\n",
    "            self.train_recall.reset()\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        \"\"\"Reset validation metrics at the beginning of each epoch\"\"\"\n",
    "        self.val_acc.reset()\n",
    "        if self.visuals:\n",
    "            self.val_f1.reset()\n",
    "            self.val_precision.reset()\n",
    "            self.val_recall.reset()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        Validation step with proper model state handling\n",
    "\n",
    "        Ensures:\n",
    "        - Model is in evaluation mode\n",
    "        - Gradients are disabled for efficiency\n",
    "        - Metrics are properly synchronized across devices\n",
    "        \"\"\"\n",
    "        # Set model to evaluation mode and disable gradients\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            vit_imgs, cnn_imgs, labels = batch\n",
    "            logits = self(vit_imgs, cnn_imgs)\n",
    "            loss = self.criterion(logits, labels)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = probs > 0.5\n",
    "\n",
    "        # Update metrics\n",
    "        self.val_acc(preds, labels)\n",
    "        if self.visuals:\n",
    "            self.val_f1(preds, labels)\n",
    "            self.val_precision(preds, labels)\n",
    "            self.val_recall(preds, labels)\n",
    "\n",
    "        # Log metrics with synchronization for distributed training\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        self.log(\"val_acc\", self.val_acc, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "        if self.visuals:\n",
    "            self.log(\"val_f1\", self.val_f1, on_epoch=True, prog_bar=True, sync_dist=True)\n",
    "            self.log(\"val_precision\", self.val_precision, on_epoch=True, sync_dist=True)\n",
    "            self.log(\"val_recall\", self.val_recall, on_epoch=True, sync_dist=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"Test step with metrics and data collection for visualization\"\"\"\n",
    "        vit_imgs, cnn_imgs, labels = batch\n",
    "        logits = self(vit_imgs, cnn_imgs)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = probs > 0.5\n",
    "\n",
    "        # Update metrics\n",
    "        self.test_acc(preds, labels)\n",
    "        if self.visuals:\n",
    "            self.test_f1(preds, labels)\n",
    "            self.test_precision(preds, labels)\n",
    "            self.test_recall(preds, labels)\n",
    "\n",
    "            # Store for visualization\n",
    "            self.test_preds.extend(preds.cpu().numpy())\n",
    "            self.test_targets.extend(labels.cpu().numpy())\n",
    "            self.test_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "        # Log metrics\n",
    "        self.log(\"test_loss\", loss, on_epoch=True)\n",
    "        self.log(\"test_acc\", self.test_acc, on_epoch=True)\n",
    "        if self.visuals:\n",
    "            self.log(\"test_f1\", self.test_f1, on_epoch=True)\n",
    "            self.log(\"test_precision\", self.test_precision, on_epoch=True)\n",
    "            self.log(\"test_recall\", self.test_recall, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Record training and validation accuracy at epoch end\"\"\"\n",
    "        # Only record if metrics are available (handles incomplete epochs)\n",
    "        if self.trainer.callback_metrics.get(\"train_acc\") is not None:\n",
    "            self.train_acc_history.append(self.trainer.callback_metrics[\"train_acc\"].item())\n",
    "        if self.trainer.callback_metrics.get(\"val_acc\") is not None:\n",
    "            self.val_acc_history.append(self.trainer.callback_metrics[\"val_acc\"].item())\n",
    "\n",
    "    def on_train_end(self):\n",
    "        \"\"\"Generate accuracy history plot after training completes\"\"\"\n",
    "        if self.visuals and self.train_acc_history and self.val_acc_history:\n",
    "            self.plot_accuracy_history()\n",
    "\n",
    "    def plot_accuracy_history(self):\n",
    "        \"\"\"Plot training and validation accuracy over epochs\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        epochs = range(1, len(self.train_acc_history) + 1)\n",
    "\n",
    "        # Plot training and validation accuracy\n",
    "        plt.plot(epochs, self.train_acc_history, 'bo-', label='Training Accuracy')\n",
    "        plt.plot(epochs, self.val_acc_history, 'go-', label='Validation Accuracy')\n",
    "\n",
    "        # Format plot\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.ylim(0, 1.05)  # Ensure accuracy range is visible\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Save and show\n",
    "        plt.savefig(\"Figures/accuracy_history.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def on_test_end(self):\n",
    "        \"\"\"Generate evaluation visualizations after testing completes\"\"\"\n",
    "        if self.visuals and self.test_targets:\n",
    "            self.generate_visualizations()\n",
    "            # Clear stored data\n",
    "            self.test_preds = []\n",
    "            self.test_targets = []\n",
    "            self.test_probs = []\n",
    "\n",
    "    def generate_visualizations(self):\n",
    "        \"\"\"Create comprehensive evaluation plots and reports\"\"\"\n",
    "        y_true = np.array(self.test_targets)\n",
    "        y_pred = np.array(self.test_preds)\n",
    "        y_probs = np.array(self.test_probs)\n",
    "\n",
    "        # 1. Classification Report\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_true, y_pred, target_names=[\"Non-Fire\", \"Fire\"]))\n",
    "\n",
    "        # 2. Confusion Matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=['Non-Fire', 'Fire'],\n",
    "                    yticklabels=['Non-Fire', 'Fire'])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.savefig(\"Figures/confusion_matrix.png\")\n",
    "        plt.show()\n",
    "\n",
    "        # 3. ROC Curve\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "                 label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.savefig(\"Figures/roc_curve.png\")\n",
    "        plt.show()\n",
    "\n",
    "        # 4. Precision-Recall Curve\n",
    "        precision, recall, _ = precision_recall_curve(y_true, y_probs)\n",
    "        avg_precision = np.mean(precision)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(recall, precision, color='blue', lw=2,\n",
    "                 label=f'Precision-Recall (Avg Precision = {avg_precision:.2f})')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.legend(loc=\"lower left\")\n",
    "        plt.savefig(\"Figures/precision_recall_curve.png\")\n",
    "        plt.show()\n",
    "\n",
    "        # 5. Probability Distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        df = pd.DataFrame({\n",
    "            'Probability': y_probs,\n",
    "            'Class': ['Fire' if t == 1 else 'Non-Fire' for t in y_true]\n",
    "        })\n",
    "        sns.histplot(\n",
    "            data=df,\n",
    "            x='Probability', hue='Class', element='step', stat='density',\n",
    "            common_norm=False, bins=20, palette=['red', 'green']\n",
    "        )\n",
    "        plt.title('Predicted Probability Distribution')\n",
    "        plt.axvline(0.5, color='black', linestyle='--')\n",
    "        plt.savefig(\"Figures/probability_distribution.png\")\n",
    "        plt.show()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure optimizer and learning rate scheduler\"\"\"\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.classifier.parameters(),  # Only optimize fusion classifier\n",
    "            lr=self.config[\"lr\"],\n",
    "            weight_decay=self.config[\"weight_decay\"]\n",
    "        )\n",
    "\n",
    "        # Learning rate scheduler (monitors validation accuracy)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='max',       # Maximize validation accuracy\n",
    "            factor=0.5,       # Reduce LR by half\n",
    "            patience=3,       # Wait 3 epochs without improvement\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_acc\",  # Track validation accuracy\n",
    "                \"frequency\": 1          # Check every epoch\n",
    "            }\n",
    "        }"
   ],
   "id": "d6b3f4fc0dbb1ff0",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training function",
   "id": "a5cdef43bbacd3d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:35:57.144201Z",
     "start_time": "2025-08-02T14:35:57.137791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training function for multimodal fusion model\n",
    "def train_fusion_model(vit_extractor, cnn_extractor, train_loader, val_loader, test_loader,\n",
    "                      max_epochs, config=None, visuals=True):\n",
    "    \"\"\"\n",
    "    End-to-end training pipeline for multimodal fusion model with enhanced validation.\n",
    "\n",
    "    Args:\n",
    "        vit_extractor: Pretrained ViT feature extractor\n",
    "        cnn_extractor: Pretrained CNN feature extractor\n",
    "        max_epochs: Maximum training epochs\n",
    "        config: Hyperparameter configuration dictionary\n",
    "        visuals: Enable advanced evaluation metrics\n",
    "\n",
    "    Returns:\n",
    "        model: Trained fusion model\n",
    "        test_results: Test performance metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # Check Validation set size\n",
    "    val_size = len(val_loader.dataset)\n",
    "    print(f\"Validation samples: {val_size}\")\n",
    "\n",
    "    # Check class distribution\n",
    "    all_val_labels = []\n",
    "    for batch in val_loader:\n",
    "        # Updated for 4-tuple batches: (vit, cnn, labels, identifiers)\n",
    "        labels = batch[2]  # Labels are the 3rd element\n",
    "        all_val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    fire_count = sum(all_val_labels)\n",
    "    non_fire_count = len(all_val_labels) - fire_count\n",
    "    print(f\"Fire samples: {fire_count} ({fire_count/len(all_val_labels):.1%})\")\n",
    "    print(f\"Non-Fire samples: {non_fire_count} ({non_fire_count/len(all_val_labels):.1%})\")\n",
    "\n",
    "\n",
    "    # Initialize fusion model\n",
    "    print(\"Initializing fusion model...\")\n",
    "    model = FusionModel(\n",
    "        vit_extractor=vit_extractor,\n",
    "        cnn_extractor=cnn_extractor,\n",
    "        config=config,\n",
    "        visuals=visuals\n",
    "    )\n",
    "\n",
    "    # Validate dataloaders\n",
    "    print(\"\\nValidating dataloaders:\")\n",
    "    print(f\"Training batches: {len(train_loader)}\")\n",
    "    print(f\"Validation batches: {len(val_loader) if val_loader is not None else 0}\")\n",
    "    print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "    # Check for empty validation loader\n",
    "    if val_loader is None or len(val_loader) == 0:\n",
    "        print(\"\\nWARNING: Validation loader is empty. Switching to test-only mode\")\n",
    "        val_loader = None\n",
    "        monitor_metric = \"train_acc\"\n",
    "        callbacks = []\n",
    "    else:\n",
    "        monitor_metric = \"val_acc\"\n",
    "        # Configure training callbacks\n",
    "        callbacks = [\n",
    "            # Early stopping based on validation accuracy\n",
    "            pl.callbacks.EarlyStopping(\n",
    "                monitor=monitor_metric,\n",
    "                patience=5,\n",
    "                mode=\"max\",\n",
    "                verbose=True\n",
    "            ),\n",
    "            # Model checkpointing\n",
    "            pl.callbacks.ModelCheckpoint(\n",
    "                monitor=monitor_metric,\n",
    "                mode=\"max\",\n",
    "                filename=\"best_fusion_model\",\n",
    "                save_top_k=1,\n",
    "                save_last=True\n",
    "            ),\n",
    "            # Learning rate monitor\n",
    "            pl.callbacks.LearningRateMonitor(logging_interval='epoch')\n",
    "        ]\n",
    "\n",
    "    # Create PyTorch Lightning trainer with validation enhancements\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"auto\",        # Automatic hardware selection\n",
    "        devices=\"auto\",            # Use available devices\n",
    "        log_every_n_steps=5,       # Log metrics every 5 batches\n",
    "        callbacks=callbacks,\n",
    "        enable_progress_bar=True,\n",
    "        check_val_every_n_epoch=1,  # Validate every single epoch\n",
    "        num_sanity_val_steps=2,     # Run 2 validation batches before training starts\n",
    "        deterministic=True,         # Ensure reproducible results\n",
    "        enable_model_summary=True\n",
    "    )\n",
    "\n",
    "    # Train the model with explicit validation loader\n",
    "    print(\"\\nStarting fusion model training...\")\n",
    "    trainer.fit(\n",
    "        model,\n",
    "        train_dataloaders=train_loader,\n",
    "        val_dataloaders=val_loader  # Explicit validation loader\n",
    "    )\n",
    "\n",
    "    # Load best checkpoint based on validation accuracy\n",
    "    if val_loader is not None and len(val_loader) > 0:\n",
    "        print(\"\\nLoading best checkpoint...\")\n",
    "        best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "        if best_model_path:\n",
    "            model = FusionModel.load_from_checkpoint(\n",
    "                best_model_path,\n",
    "                vit_extractor=vit_extractor,\n",
    "                cnn_extractor=cnn_extractor,\n",
    "                config=config,\n",
    "                visuals=visuals\n",
    "            )\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_results = trainer.test(model, test_loader)\n",
    "\n",
    "    return model, test_results"
   ],
   "id": "3618693e1a3a69ae",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Multi-Model",
   "id": "44a64dab6dca6cfd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model",
   "id": "d2d569b3b29ba5eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:35:59.787853Z",
     "start_time": "2025-08-02T14:35:59.781997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Deployment class for real-time fire prediction\n",
    "class FirePredictor:\n",
    "    def __init__(self, fusion_model, vit_extractor, cnn_extractor):\n",
    "        \"\"\"\n",
    "        Fire detection predictor for multimodal (RGB + thermal) inputs.\n",
    "\n",
    "        Args:\n",
    "            fusion_model: Trained fusion model\n",
    "            vit_extractor: ViT feature extractor for RGB images\n",
    "            cnn_extractor: CNN feature extractor for thermal images\n",
    "        \"\"\"\n",
    "        self.fusion_model = fusion_model\n",
    "        self.vit_extractor = vit_extractor\n",
    "        self.cnn_extractor = cnn_extractor\n",
    "\n",
    "        # Preprocessing for RGB images (ViT input)\n",
    "        self.vit_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),   # Resize to standard size\n",
    "            transforms.ToTensor(),           # Convert to tensor\n",
    "            transforms.Normalize(            # ImageNet normalization\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        # Preprocessing for thermal images (CNN input)\n",
    "        self.cnn_transform = v2.Compose([\n",
    "            v2.Resize(size=(224, 224)),     # Resize to model input size\n",
    "            v2.ToImage(),                    # Convert to tensor\n",
    "            v2.ToDtype(torch.float32, scale=True),  # Normalize to [0,1]\n",
    "            v2.Grayscale(num_output_channels=1),     # Ensure single channel\n",
    "            v2.Normalize(mean=[0.5], std=[0.5]),    # Scale to [-1,1]\n",
    "        ])\n",
    "\n",
    "    def predict(self, vit_image_path, cnn_image_path):\n",
    "        \"\"\"\n",
    "        Predicts fire probability from paired RGB and thermal images.\n",
    "\n",
    "        Args:\n",
    "            vit_image_path: Path to RGB image file\n",
    "            cnn_image_path: Path to thermal image file\n",
    "\n",
    "        Returns:\n",
    "            prediction: \"Fire\" or \"Not Fire\"\n",
    "            probability: Confidence score (0.0-1.0)\n",
    "        \"\"\"\n",
    "        self.fusion_model.eval()  # Set to evaluation mode\n",
    "\n",
    "        # Process RGB image\n",
    "        vit_img = Image.open(vit_image_path).convert('RGB')\n",
    "        vit_tensor = self.vit_transform(vit_img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Process thermal image\n",
    "        cnn_img = Image.open(cnn_image_path)\n",
    "        cnn_tensor = self.cnn_transform(cnn_img).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            logits = self.fusion_model(vit_tensor, cnn_tensor)\n",
    "            prob = torch.sigmoid(logits).item()  # Convert to probability\n",
    "            prediction = \"Fire\" if prob > 0.5 else \"Not Fire\"\n",
    "\n",
    "        return prediction, prob"
   ],
   "id": "c9f78c2158d72c31",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training",
   "id": "f8d1e12994e3295f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:41:23.644156Z",
     "start_time": "2025-08-02T14:36:33.175056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize feature extractors (load with trained weights)\n",
    "print(\"Loading pretrained feature extractors...\")\n",
    "# Load ViT extractor from Lightning checkpoint\n",
    "vit_extractor = FireFeatureExtractorViT.load_from_checkpoint(\"Saved_Features/ViT_fire_feature_extractor.pth\")\n",
    "\n",
    "# Initialize CNN extractor and load weights\n",
    "cnn_extractor = FireFeatureExtractorCNN()\n",
    "cnn_extractor.load_state_dict(\n",
    "    torch.load(\"Saved_Features/CNN_fire_feature_extractor.pth\"),\n",
    "    strict=False  # Ignore classifier weights\n",
    ")\n",
    "\n",
    "# Remove classifier from CNN model\n",
    "cnn_extractor.classifier = nn.Identity()  # Replace classifier with identity function\n",
    "\n",
    "# Set both models to evaluation mode\n",
    "vit_extractor.eval()\n",
    "cnn_extractor.eval()\n",
    "print(\"Feature extractors loaded and ready\")\n",
    "\n",
    "# Fusion model configuration\n",
    "config = {\n",
    "    \"lr\": 5e-4,          # Learning rate\n",
    "    \"hidden_dim\": 768,    # Hidden layer dimension\n",
    "    \"dropout_rate\": 0.2,  # Dropout probability\n",
    "    \"pos_weight\": 1.0     # Class imbalance weight\n",
    "}\n",
    "\n",
    "# Train fusion model\n",
    "print(\"\\nTraining fusion model...\")\n",
    "fusion_model, results = train_fusion_model(\n",
    "    vit_extractor,\n",
    "    cnn_extractor,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    max_epochs=20,\n",
    "    config=config,\n",
    "    visuals=True  # Enable advanced visualizations\n",
    ")\n",
    "\n",
    "# Save model weights\n",
    "fusion_model.eval()\n",
    "torch.save(fusion_model.state_dict(), \"Saved_Features/fusion_model_weights.pth\")\n",
    "print(\"Fusion model weights saved\")\n",
    "\n",
    "# Initialize predictor for deployment\n",
    "predictor = FirePredictor(fusion_model, vit_extractor, cnn_extractor)\n",
    "print(\"Fire predictor initialized\")"
   ],
   "id": "892cc9e7deee668b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained feature extractors...\n",
      "Feature extractors loaded and ready\n",
      "\n",
      "Training fusion model...\n",
      "Validation samples: 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/carbs/Desktop/Projects/ViT-Based_ForestFire/REPO/forest_fire_detection/.venv/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name            | Type                    | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0  | vit_extractor   | FireFeatureExtractorViT | 86.0 M | eval \n",
      "1  | cnn_extractor   | FireFeatureExtractorCNN | 4.2 M  | eval \n",
      "2  | classifier      | Sequential              | 986 K  | train\n",
      "3  | criterion       | BCEWithLogitsLoss       | 0      | train\n",
      "4  | train_acc       | BinaryAccuracy          | 0      | train\n",
      "5  | val_acc         | BinaryAccuracy          | 0      | train\n",
      "6  | test_acc        | BinaryAccuracy          | 0      | train\n",
      "7  | train_f1        | BinaryF1Score           | 0      | train\n",
      "8  | val_f1          | BinaryF1Score           | 0      | train\n",
      "9  | test_f1         | BinaryF1Score           | 0      | train\n",
      "10 | train_precision | BinaryPrecision         | 0      | train\n",
      "11 | val_precision   | BinaryPrecision         | 0      | train\n",
      "12 | test_precision  | BinaryPrecision         | 0      | train\n",
      "13 | train_recall    | BinaryRecall            | 0      | train\n",
      "14 | val_recall      | BinaryRecall            | 0      | train\n",
      "15 | test_recall     | BinaryRecall            | 0      | train\n",
      "---------------------------------------------------------------------\n",
      "986 K     Trainable params\n",
      "90.2 M    Non-trainable params\n",
      "91.1 M    Total params\n",
      "364.570   Total estimated model params size (MB)\n",
      "19        Modules in train mode\n",
      "384       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire samples: 41.0 (50.0%)\n",
      "Non-Fire samples: 41.0 (50.0%)\n",
      "Initializing fusion model...\n",
      "\n",
      "Validating dataloaders:\n",
      "Training batches: 48\n",
      "Validation batches: 6\n",
      "Test batches: 6\n",
      "\n",
      "Starting fusion model training...\n",
      "Epoch 0: 100%|██████████| 48/48 [00:28<00:00,  1.68it/s, v_num=24, train_loss_step=0.802]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:02,  1.70it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|███▎      | 2/6 [00:01<00:02,  1.71it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 3/6 [00:01<00:01,  1.71it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 4/6 [00:02<00:01,  1.71it/s]\u001B[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 5/6 [00:02<00:00,  1.69it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 6/6 [00:03<00:00,  1.95it/s]\u001B[A\n",
      "Epoch 0: 100%|██████████| 48/48 [00:34<00:00,  1.41it/s, v_num=24, train_loss_step=0.802, val_loss=0.161, val_acc=1.000, val_f1=1.000, train_loss_epoch=0.755, train_acc=0.530, train_f1=0.539]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_acc improved. New best score: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 48/48 [00:29<00:00,  1.63it/s, v_num=24, train_loss_step=0.796, val_loss=0.161, val_acc=1.000, val_f1=1.000, train_loss_epoch=0.755, train_acc=0.530, train_f1=0.539]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:02,  1.67it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|███▎      | 2/6 [00:01<00:02,  1.68it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 3/6 [00:01<00:01,  1.70it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 4/6 [00:02<00:01,  1.70it/s]\u001B[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 5/6 [00:02<00:00,  1.69it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 6/6 [00:03<00:00,  1.96it/s]\u001B[A\n",
      "Epoch 2: 100%|██████████| 48/48 [00:29<00:00,  1.65it/s, v_num=24, train_loss_step=0.704, val_loss=0.254, val_acc=0.963, val_f1=0.963, train_loss_epoch=0.667, train_acc=0.560, train_f1=0.579]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:03,  1.60it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|███▎      | 2/6 [00:01<00:02,  1.62it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 3/6 [00:01<00:01,  1.63it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 4/6 [00:02<00:01,  1.63it/s]\u001B[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 5/6 [00:03<00:00,  1.63it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 6/6 [00:03<00:00,  1.87it/s]\u001B[A\n",
      "Epoch 3: 100%|██████████| 48/48 [00:29<00:00,  1.63it/s, v_num=24, train_loss_step=0.685, val_loss=0.186, val_acc=0.988, val_f1=0.988, train_loss_epoch=0.631, train_acc=0.614, train_f1=0.619]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:03,  1.61it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|███▎      | 2/6 [00:01<00:02,  1.61it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 3/6 [00:01<00:01,  1.62it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 4/6 [00:02<00:01,  1.63it/s]\u001B[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 5/6 [00:03<00:00,  1.63it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\u001B[A\n",
      "Epoch 4: 100%|██████████| 48/48 [00:29<00:00,  1.62it/s, v_num=24, train_loss_step=0.759, val_loss=0.159, val_acc=0.976, val_f1=0.975, train_loss_epoch=0.621, train_acc=0.650, train_f1=0.655]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:03,  1.61it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|███▎      | 2/6 [00:01<00:02,  1.62it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 3/6 [00:01<00:01,  1.63it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 4/6 [00:02<00:01,  1.63it/s]\u001B[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 5/6 [00:03<00:00,  1.63it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\u001B[A\n",
      "Epoch 5: 100%|██████████| 48/48 [00:29<00:00,  1.62it/s, v_num=24, train_loss_step=0.670, val_loss=0.186, val_acc=0.976, val_f1=0.975, train_loss_epoch=0.608, train_acc=0.650, train_f1=0.662]\n",
      "Validation: |          | 0/? [00:00<?, ?it/s]\u001B[A\n",
      "Validation:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:   0%|          | 0/6 [00:00<?, ?it/s]\u001B[A\n",
      "Validation DataLoader 0:  17%|█▋        | 1/6 [00:00<00:03,  1.61it/s]\u001B[A\n",
      "Validation DataLoader 0:  33%|███▎      | 2/6 [00:01<00:02,  1.62it/s]\u001B[A\n",
      "Validation DataLoader 0:  50%|█████     | 3/6 [00:01<00:01,  1.62it/s]\u001B[A\n",
      "Validation DataLoader 0:  67%|██████▋   | 4/6 [00:02<00:01,  1.63it/s]\u001B[A\n",
      "Validation DataLoader 0:  83%|████████▎ | 5/6 [00:03<00:00,  1.63it/s]\u001B[A\n",
      "Validation DataLoader 0: 100%|██████████| 6/6 [00:03<00:00,  1.90it/s]\u001B[A\n",
      "Epoch 5: 100%|██████████| 48/48 [00:35<00:00,  1.36it/s, v_num=24, train_loss_step=0.670, val_loss=0.131, val_acc=0.976, val_f1=0.975, train_loss_epoch=0.583, train_acc=0.680, train_f1=0.691]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_acc did not improve in the last 5 records. Best score: 1.000. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 48/48 [00:38<00:00,  1.24it/s, v_num=24, train_loss_step=0.670, val_loss=0.131, val_acc=0.976, val_f1=0.975, train_loss_epoch=0.583, train_acc=0.680, train_f1=0.691]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading best checkpoint...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating on test set...\n",
      "Testing DataLoader 0: 100%|██████████| 6/6 [00:05<00:00,  1.12it/s]\n",
      "\n",
      "==================================================\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non-Fire       1.00      1.00      1.00        41\n",
      "        Fire       1.00      1.00      1.00        40\n",
      "\n",
      "    accuracy                           1.00        81\n",
      "   macro avg       1.00      1.00      1.00        81\n",
      "weighted avg       1.00      1.00      1.00        81\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc                    1.0\n",
      "         test_f1                    1.0\n",
      "        test_loss            0.155252143740654\n",
      "     test_precision                 1.0\n",
      "       test_recall                  1.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "Fusion model weights saved\n",
      "Fire predictor initialized\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:42:54.913744Z",
     "start_time": "2025-08-02T14:42:54.408119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example prediction using the trained fusion model\n",
    "print(\"\\nRunning example prediction...\")\n",
    "# Paths to test images\n",
    "vit_path = \"dataset/raw/RGB/fire/00008.JPG\"      # RGB image path\n",
    "cnn_path = \"dataset/raw/thermal/fire/00008.JPG\"  # Thermal image path\n",
    "\n",
    "# Make prediction\n",
    "prediction, probability = predictor.predict(vit_path, cnn_path)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nPredicting FIRE images:\")\n",
    "print(f\"  RGB Image: {os.path.basename(vit_path)}\")\n",
    "print(f\"  Thermal Image: {os.path.basename(cnn_path)}\")\n",
    "print(f\"Prediction: {prediction} (Probability: {probability:.4f})\")\n",
    "print(f\"Interpretation: {'FIRE DETECTED' if prediction == 'Fire' else 'No fire detected'}\")"
   ],
   "id": "6eb96ed2c6dead83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running example prediction...\n",
      "\n",
      "Predicting FIRE images:\n",
      "  RGB Image: 00008.JPG\n",
      "  Thermal Image: 00008.JPG\n",
      "Prediction: Fire (Probability: 0.8111)\n",
      "Interpretation: FIRE DETECTED\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-02T14:42:49.793063Z",
     "start_time": "2025-08-02T14:42:48.421038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example prediction using the trained fusion model\n",
    "print(\"\\nRunning example prediction...\")\n",
    "# Paths to test images\n",
    "vit_path = \"dataset/raw/RGB/no_fire/00052.JPG\"      # RGB image path\n",
    "cnn_path = \"dataset/raw/thermal/no_fire/00052.JPG\"  # Thermal image path\n",
    "\n",
    "# Make prediction\n",
    "prediction, probability = predictor.predict(vit_path, cnn_path)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nPredicting NON-FIRE images:\")\n",
    "print(f\"  RGB Image: {os.path.basename(vit_path)}\")\n",
    "print(f\"  Thermal Image: {os.path.basename(cnn_path)}\")\n",
    "print(f\"Prediction: {prediction} (Probability: {probability:.4f})\")\n",
    "print(f\"Interpretation: {'FIRE DETECTED' if prediction == 'Fire' else 'No fire detected'}\")"
   ],
   "id": "1e26f3f2f23859e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running example prediction...\n",
      "\n",
      "Predicting NON-FIRE images:\n",
      "  RGB Image: 00052.JPG\n",
      "  Thermal Image: 00052.JPG\n",
      "Prediction: Not Fire (Probability: 0.1490)\n",
      "Interpretation: No fire detected\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
